# ê°œì„ ëœ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ v2.0

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm-optimization-system/
â”œâ”€â”€ ğŸ“„ main.py                          # ê°œì„ ëœ ë©”ì¸ CLI
â”œâ”€â”€ ğŸ“„ improved_requirements.txt        # ì˜ì¡´ì„± ì¶©ëŒ í•´ê²°ëœ ìš”êµ¬ì‚¬í•­
â”œâ”€â”€ ğŸ“ config/                          # ì„¤ì • íŒŒì¼ ë¶„ë¦¬
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ base_config.py              # ê¸°ë³¸ ì„¤ì • ë° ê²€ì¦
â”‚   â””â”€â”€ ğŸ“„ model_config.py             # ëª¨ë¸ ì„¤ì • ì „ìš©
â”œâ”€â”€ ğŸ“ core/                           # í•µì‹¬ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ memory_manager.py           # ì™„ì „í•œ ë©”ëª¨ë¦¬ í•´ì œ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ ğŸ“„ async_manager.py            # ìŠ¤ë ˆë“œ ì•ˆì „ ë¹„ë™ê¸° ê´€ë¦¬
â”‚   â”œâ”€â”€ ğŸ“„ error_handler.py            # ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬
â”‚   â””â”€â”€ ğŸ“„ improved_optimizer.py       # Optuna ê¸°ë°˜ ìµœì í™”
â”œâ”€â”€ ğŸ“ data/                           # ë°ì´í„°ì…‹ (ìë™ ìƒì„±)
â”œâ”€â”€ ğŸ“ optimization_results/           # ìµœì í™” ê²°ê³¼ (ìë™ ìƒì„±)
â”œâ”€â”€ ğŸ“ logs/                          # ë¡œê·¸ íŒŒì¼ (ìë™ ìƒì„±)
â””â”€â”€ ğŸ“ .cache/                        # ìºì‹œ íŒŒì¼ (ìë™ ìƒì„±)
```

## ğŸš€ ì„¤ì¹˜ ê°€ì´ë“œ

### 1. í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# 1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir llm-optimization-system
cd llm-optimization-system

# 2. íŒŒì´ì¬ ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r improved_requirements.txt
```

### 2. GPU ì§€ì› ì„¤ì¹˜ (ì„ íƒì‚¬í•­)

```bash
# CUDA 11.8 (ê¶Œì¥)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CPU ì „ìš©
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 3. ì‹œìŠ¤í…œ ì´ˆê¸°í™”

```bash
# ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í•˜ë“œì›¨ì–´ ìë™ ê°ì§€)
python main.py init --auto-detect

# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
python main.py status --detailed
```

## ğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­

### âœ… Critical ë¬¸ì œ í•´ê²°

#### 1. **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€**
- **íŒŒì¼**: `core/memory_manager.py`
- **ê°œì„ ë‚´ìš©**:
  - ëª¨ë“  GPU ì¥ì¹˜ì—ì„œ ì™„ì „í•œ ë©”ëª¨ë¦¬ í•´ì œ
  - Weak referenceë¥¼ í†µí•œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
  - ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì •ë¦¬
  - ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œìŠ¤í…œ

```python
# ì‚¬ìš© ì˜ˆì‹œ
from core.memory_manager import get_resource_manager

manager = get_resource_manager()
with manager.memory_guard("model_name", required_gb=8.0):
    # ëª¨ë¸ ì‘ì—… ìˆ˜í–‰
    pass  # ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬ë¨
```

#### 2. **ì˜ì¡´ì„± ì¶©ëŒ í•´ê²°**
- **íŒŒì¼**: `improved_requirements.txt`
- **ê°œì„ ë‚´ìš©**:
  - scikit-optimize ì œê±°, Optunaë¡œ í†µì¼
  - í˜¸í™˜ì„±ì´ ê²€ì¦ëœ ë²„ì „ìœ¼ë¡œ ê³ ì •
  - ì„ íƒì  íŒ¨í‚¤ì§€ ëª…ì‹œ

#### 3. **ìŠ¤ë ˆë“œ ì•ˆì „ì„± ê°œì„ **
- **íŒŒì¼**: `core/async_manager.py`
- **ê°œì„ ë‚´ìš©**:
  - ì „ìš© ì´ë²¤íŠ¸ ë£¨í”„ ìŠ¤ë ˆë“œ ìš´ì˜
  - ìŠ¤ë ˆë“œ ì•ˆì „í•œ íƒœìŠ¤í¬ ê´€ë¦¬
  - ì´ë²¤íŠ¸ ë£¨í”„ ì¤‘ì²© ë¬¸ì œ í•´ê²°

```python
# ì‚¬ìš© ì˜ˆì‹œ
from core.async_manager import run_async_safe

result = run_async_safe(some_coroutine(), timeout=60)
```

### âœ… Important ë¬¸ì œ í•´ê²°

#### 1. **ì„¤ì • íŒŒì¼ ë¶„ë¦¬**
- **íŒŒì¼**: `config/base_config.py`, `config/model_config.py`
- **ê°œì„ ë‚´ìš©**:
  - 4600ì¤„ ë‹¨ì¼ íŒŒì¼ì„ ëª¨ë“ˆë³„ë¡œ ë¶„ë¦¬
  - íƒ€ì… ì•ˆì „ì„± ê°•í™” (Enum ì‚¬ìš©)
  - ì„¤ì • ê²€ì¦ ì‹œìŠ¤í…œ ì¶”ê°€

```python
# ì‚¬ìš© ì˜ˆì‹œ
from config.model_config import ModelConfig, ModelType

config = ModelConfig(
    name="qwen2.5-7b",
    model_path="Qwen/Qwen2.5-7B-Instruct",
    model_type=ModelType.TRANSFORMERS
)
assert config.validate()  # ìë™ ê²€ì¦
```

#### 2. **ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”**
- **íŒŒì¼**: `core/error_handler.py`
- **ê°œì„ ë‚´ìš©**:
  - ì˜¤ë¥˜ íŒ¨í„´ ì¸ì‹ ë° ìë™ ë¶„ë¥˜
  - êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì•ˆ
  - ì˜¤ë¥˜ íˆìŠ¤í† ë¦¬ ë° í†µê³„ ê´€ë¦¬
  - ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ

```python
# ì‚¬ìš© ì˜ˆì‹œ
from core.error_handler import safe_execute

@safe_execute(fallback_result="default")
def risky_function():
    # ìœ„í—˜í•œ ì‘ì—…
    pass
```

## ğŸ¯ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•

```bash
# 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
python main.py init --auto-detect

# 2. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
python main.py status --detailed

# 3. ì•ˆì „í•œ ìµœì í™” ì‹¤í–‰
python main.py optimize --model qwen2.5-7b --dataset korean_math --trials 10 --safe

# 4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
python main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 20

# 5. ëª¨ë¸ ë¹„êµ
python main.py compare --models qwen2.5-7b llama3-8b --dataset korean_math

# 6. ì‹œìŠ¤í…œ ì •ë¦¬
python main.py clean --all
```

### ê³ ê¸‰ ì‚¬ìš©ë²•

```bash
# ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
python main.py optimize --model qwen2.5-7b --dataset korean_math --debug

# íƒ€ì„ì•„ì›ƒ ì„¤ì •
python main.py optimize --model qwen2.5-7b --dataset korean_math --timeout 1800

# ê·¸ë¦¬ë“œ ì„œì¹˜ ì‚¬ìš©
python main.py optimize --model qwen2.5-7b --dataset korean_math --method grid

# ê²°ê³¼ ì¡°íšŒ
python main.py list --type results
```

## ğŸ“Š ì„±ëŠ¥ ê°œì„  íš¨ê³¼

### Before (ê¸°ì¡´ ë²„ì „)
- âŒ GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¡œ ì‹œìŠ¤í…œ ë¶ˆì•ˆì •
- âŒ scikit-optimize ì˜ì¡´ì„± ì¶©ëŒ
- âŒ ì´ë²¤íŠ¸ ë£¨í”„ ì¤‘ì²©ìœ¼ë¡œ ë°ë“œë½ ë°œìƒ
- âŒ 4600ì¤„ ë‹¨ì¼ ì„¤ì • íŒŒì¼ë¡œ ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€
- âŒ ëª¨í˜¸í•œ ì˜¤ë¥˜ ë©”ì‹œì§€

### After (ê°œì„ ëœ v2.0)
- âœ… ì™„ì „í•œ ë©”ëª¨ë¦¬ í•´ì œë¡œ ì•ˆì •ì  ì¥ê¸° ì‹¤í–‰
- âœ… Optuna ê¸°ë°˜ í†µí•© ìµœì í™”
- âœ… ìŠ¤ë ˆë“œ ì•ˆì „í•œ ë¹„ë™ê¸° ì²˜ë¦¬
- âœ… ëª¨ë“ˆí™”ëœ ì„¤ì •ìœ¼ë¡œ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
- âœ… êµ¬ì²´ì  í•´ê²°ì±… ì œê³µí•˜ëŠ” ì˜¤ë¥˜ ì²˜ë¦¬

## ğŸ›¡ï¸ ì•ˆì „ì„± ë³´ì¥

### ë©”ëª¨ë¦¬ ì•ˆì „ì„±
```python
# ìë™ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
- ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
- ìœ„í—˜ ìˆ˜ì¤€ë³„ ê²½ê³  (SAFE/WARNING/CRITICAL/EMERGENCY)
- ì„ê³„ê°’ ì´ˆê³¼ì‹œ ìë™ ê¸´ê¸‰ ì •ë¦¬
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ ë° ë³´ê³ 
```

### ìŠ¤ë ˆë“œ ì•ˆì „ì„±
```python
# ì „ìš© ì´ë²¤íŠ¸ ë£¨í”„ ìŠ¤ë ˆë“œ
- ë©”ì¸ ìŠ¤ë ˆë“œì™€ ë¶„ë¦¬ëœ ë¹„ë™ê¸° ì²˜ë¦¬
- ìŠ¤ë ˆë“œ ì•ˆì „í•œ íƒœìŠ¤í¬ í ê´€ë¦¬
- ë°ë“œë½ ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜
- ì•ˆì „í•œ ì¢…ë£Œ ì²˜ë¦¬
```

### ì˜¤ë¥˜ ë³µì›ë ¥
```python
# ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬
- ì˜¤ë¥˜ íŒ¨í„´ ìë™ ì¸ì‹
- ì¹´í…Œê³ ë¦¬ë³„ ë³µêµ¬ ì „ëµ
- ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
- í´ë°± ì˜µì…˜ ì œê³µ
```

## ğŸ”§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ì¦ìƒ: "CUDA out of memory" ì˜¤ë¥˜
# í•´ê²°ì±…:
python main.py optimize --model qwen2.5-7b --dataset korean_math --safe
# ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬
python main.py clean --cache
```

#### 2. ì˜ì¡´ì„± ì¶©ëŒ
```bash
# ì¦ìƒ: ImportError ë˜ëŠ” ë²„ì „ ì¶©ëŒ
# í•´ê²°ì±…:
pip uninstall scikit-optimize  # ê¸°ì¡´ ì¶©ëŒ íŒ¨í‚¤ì§€ ì œê±°
pip install -r improved_requirements.txt  # ê°œì„ ëœ ì˜ì¡´ì„± ì„¤ì¹˜
```

#### 3. ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```bash
# ì¦ìƒ: "trust_remote_code" ì˜¤ë¥˜
# í•´ê²°ì±…: ëª¨ë¸ ì„¤ì •ì—ì„œ trust_remote_code=true ì„¤ì •
# ë˜ëŠ” ì•ˆì „í•œ ëª¨ë¸ ì‚¬ìš©
python main.py list --type models  # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
```

### ë””ë²„ê¹… ë„êµ¬

```bash
# ìƒì„¸í•œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
python main.py status --detailed

# ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
python main.py optimize --model qwen2.5-7b --dataset korean_math --debug

# ì˜¤ë¥˜ íˆìŠ¤í† ë¦¬ í™•ì¸
python main.py list --type results
```

## ğŸ“ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ëª¨ë¸ ì„¤ì • ì¶”ê°€

```python
# config/models.json í¸ì§‘ ë˜ëŠ” ì½”ë“œë¡œ ì¶”ê°€
from config.model_config import ModelConfig, ModelType, DataType

new_model = ModelConfig(
    name="custom-model",
    model_path="your/model/path",
    model_type=ModelType.TRANSFORMERS,
    device=DeviceType.AUTO,
    dtype=DataType.FLOAT16,
    quantization=QuantizationConfig(load_in_4bit=True),
    description="Custom model for specific task"
)

manager = ModelConfigManager()
manager.add_config("custom-model", new_model)
manager.save_to_file("config/models.json")
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
TOKENIZERS_PARALLELISM=false
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
HF_HOME=~/.cache/huggingface
OMP_NUM_THREADS=4
```

## ğŸš€ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. í•˜ë“œì›¨ì–´ë³„ ìµœì  ì„¤ì •

#### GPU 8GB ì´í•˜
```python
# 4-bit ì–‘ìí™” í•„ìˆ˜
load_in_4bit=True
max_batch_size=1
gradient_checkpointing=True
```

#### GPU 16GB ì´ìƒ
```python
# ì„ íƒì  ì–‘ìí™”
load_in_4bit=False  # ì„±ëŠ¥ ìš°ì„ 
dtype="float16"
max_batch_size=4
```

#### ë‹¤ì¤‘ GPU
```python
# í…ì„œ ë³‘ë ¬í™”
tensor_parallel_size=2
pipeline_parallel_size=1
```

### 2. ìµœì í™” ì „ëµ

#### ì •í™•ë„ ìš°ì„ 
```python
InferenceParams(
    temperature=0.1,
    top_p=0.3,
    top_k=10
)
```

#### ì°½ì˜ì„± ìš°ì„ 
```python
InferenceParams(
    temperature=0.8,
    top_p=0.9,
    top_k=50
)
```

#### ì†ë„ ìš°ì„ 
```python
# vLLM ì—”ì§„ + ë™ì  ë°°ì¹­
model_type=ModelType.VLLM
max_batch_size=16
```

## ğŸ“š API ì°¸ì¡°

### í•µì‹¬ í´ë˜ìŠ¤

```python
# ë©”ëª¨ë¦¬ ê´€ë¦¬
from core.memory_manager import get_resource_manager
manager = get_resource_manager()
manager.get_memory_stats()
manager.cleanup_all_devices()

# ë¹„ë™ê¸° ì²˜ë¦¬
from core.async_manager import run_async_safe, submit_async_task
result = run_async_safe(coroutine, timeout=60)
task_id = submit_async_task(coroutine, name="task")

# ì˜¤ë¥˜ ì²˜ë¦¬
from core.error_handler import safe_execute, error_context
@safe_execute(fallback_result="default")
def risky_function():
    pass

# ìµœì í™”
from core.improved_optimizer import SafeOptimizer
optimizer = SafeOptimizer()
result = await optimizer.optimize_parameters(model, dataset, evaluator)
```

## ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### ê¸°ì¡´ ë²„ì „ì—ì„œ v2.0ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ

```bash
# 1. ê¸°ì¡´ í™˜ê²½ ë°±ì—…
cp llm_config.json llm_config.json.backup

# 2. ìƒˆ ë²„ì „ íŒŒì¼ë“¤ ë°°ì¹˜
# (ìœ„ì˜ íŒŒì¼ êµ¬ì¡°ëŒ€ë¡œ íŒŒì¼ë“¤ì„ ë°°ì¹˜)

# 3. ì˜ì¡´ì„± ì—…ë°ì´íŠ¸
pip uninstall scikit-optimize  # ì¶©ëŒ íŒ¨í‚¤ì§€ ì œê±°
pip install -r improved_requirements.txt

# 4. ì„¤ì • ë§ˆì´ê·¸ë ˆì´ì…˜
python main.py init --force  # ìƒˆ ì„¤ì • í˜•ì‹ìœ¼ë¡œ ë³€í™˜

# 5. ê²€ì¦
python main.py status --detailed
```

## ğŸ—ï¸ ê°œë°œì ê°€ì´ë“œ

### ìƒˆë¡œìš´ ëª¨ë¸ íƒ€ì… ì¶”ê°€

```python
# 1. config/model_config.pyì— ìƒˆ enum ì¶”ê°€
class ModelType(Enum):
    NEW_ENGINE = "new_engine"

# 2. core/improved_optimizer.pyì— ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
def _create_model_interface(self, config):
    if config.model_type == ModelType.NEW_ENGINE:
        return NewEngineInterface(config)
```

### ìƒˆë¡œìš´ í‰ê°€ì ì¶”ê°€

```python
# 1. í‰ê°€ì í´ë˜ìŠ¤ ìƒì„±
class CustomEvaluator:
    async def evaluate(self, model, dataset, params):
        # í‰ê°€ ë¡œì§
        return score

# 2. ìµœì í™”ì— ì‚¬ìš©
evaluator = CustomEvaluator()
result = await optimizer.optimize_parameters(
    model, dataset, evaluator.evaluate
)
```

## ğŸ“ ì§€ì› ë° í”¼ë“œë°±

### ë¬¸ì œ ë³´ê³ 
1. `python main.py status --detailed` ì¶œë ¥ ì²¨ë¶€
2. ì˜¤ë¥˜ ë¡œê·¸ (`logs/` ë””ë ‰í† ë¦¬) ì²¨ë¶€
3. ì‚¬ìš© í™˜ê²½ ì •ë³´ (OS, Python ë²„ì „, GPU ì •ë³´)

### ê¸°ì—¬ ë°©ë²•
1. ì´ìŠˆ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì´ìŠˆ í™•ì¸
2. ë¸Œëœì¹˜ ìƒì„± í›„ ê°œë°œ
3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰: `python -m pytest tests/`
4. Pull Request ìƒì„±

## ğŸ“ˆ ë¡œë“œë§µ

### v2.1 (ì˜ˆì •)
- [ ] ì›¹ UI ì¸í„°í˜ì´ìŠ¤
- [ ] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- [ ] ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- [ ] í´ë¼ìš°ë“œ ë°°í¬ ì§€ì›

### v2.2 (ì˜ˆì •) 
- [ ] ë” ë§ì€ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì§€ì›
- [ ] ë¶„ì‚° í•™ìŠµ ìµœì í™”
- [ ] A/B í…ŒìŠ¤íŠ¸ ìë™í™”
- [ ] ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸

---

**ğŸ‰ v2.0ì˜ ëª¨ë“  Critical ë° Important ë¬¸ì œê°€ í•´ê²°ë˜ì–´ ì•ˆì „í•˜ê³  ì•ˆì •ì ì¸ LLM ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!**