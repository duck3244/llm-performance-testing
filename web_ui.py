import time
import threading
import numpy as np
import streamlit as st
import plotly.graph_objects as go

from main import *
from config import *


class WebUI:
    """ì›¹ ê¸°ë°˜ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self):
        self.config_manager = RobustConfigManager()
        self.optimizer = SafePerformanceOptimizer()

    def run(self):
        """ì›¹ UI ì‹¤í–‰"""
        st.set_page_config(
            page_title="LLM ìµœì í™” ì‹œìŠ¤í…œ",
            page_icon="ğŸš€",
            layout="wide"
        )

        st.title("ğŸš€ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ")

        # ì‚¬ì´ë“œë°” ë©”ë‰´
        menu = st.sidebar.selectbox(
            "ë©”ë‰´ ì„ íƒ",
            ["ğŸ  ëŒ€ì‹œë³´ë“œ", "ğŸ”§ ëª¨ë¸ ì„¤ì •", "âš¡ ìµœì í™”", "ğŸ“Š ê²°ê³¼ ë¶„ì„"]
        )

        if menu == "ğŸ  ëŒ€ì‹œë³´ë“œ":
            self.show_dashboard()
        elif menu == "ğŸ”§ ëª¨ë¸ ì„¤ì •":
            self.show_model_config()
        elif menu == "âš¡ ìµœì í™”":
            self.show_optimization()
        elif menu == "ğŸ“Š ê²°ê³¼ ë¶„ì„":
            self.show_results()

    def show_dashboard(self):
        """ëŒ€ì‹œë³´ë“œ í‘œì‹œ"""
        st.header("ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ")

        # í•˜ë“œì›¨ì–´ ì •ë³´
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("GPU ë©”ëª¨ë¦¬", "16GB", "ì‚¬ìš© ê°€ëŠ¥")

        with col2:
            st.metric("CPU ì½”ì–´", "8ê°œ", "ì •ìƒ")

        with col3:
            st.metric("ë“±ë¡ëœ ëª¨ë¸", "4ê°œ", "+1")

        # ìµœê·¼ ê²°ê³¼
        st.subheader("ìµœê·¼ ìµœì í™” ê²°ê³¼")

        # ë”ë¯¸ ë°ì´í„°
        data = {
            'Model': ['Llama2-7B', 'Mistral-7B', 'Gemma-7B'],
            'Score': [0.85, 0.82, 0.79],
            'Speed': [75.5, 68.2, 71.3]
        }

        st.dataframe(data)

        # ì„±ëŠ¥ ì°¨íŠ¸
        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=data['Model'],
            y=data['Score'],
            name='ìµœì í™” ì ìˆ˜'
        ))

        st.plotly_chart(fig, use_container_width=True)

    def show_model_config(self):
        """ëª¨ë¸ ì„¤ì • í˜ì´ì§€"""
        st.header("ëª¨ë¸ ì„¤ì •")

        # ëª¨ë¸ ì„ íƒ
        models = list(self.config_manager.model_configs.keys())
        selected_model = st.selectbox("ëª¨ë¸ ì„ íƒ", models)

        if selected_model:
            config = self.config_manager.model_configs[selected_model]

            # ì„¤ì • í¸ì§‘
            col1, col2 = st.columns(2)

            with col1:
                new_dtype = st.selectbox(
                    "ë°ì´í„° íƒ€ì…",
                    ["float16", "float32", "bfloat16"],
                    index=["float16", "float32", "bfloat16"].index(config.dtype)
                )

                new_load_4bit = st.checkbox(
                    "4-bit ì–‘ìí™”",
                    value=config.load_in_4bit
                )

            with col2:
                new_device = st.selectbox(
                    "ì¥ì¹˜",
                    ["auto", "cuda", "cpu"],
                    index=["auto", "cuda", "cpu"].index(config.device)
                )

                new_load_8bit = st.checkbox(
                    "8-bit ì–‘ìí™”",
                    value=config.load_in_8bit
                )

            if st.button("ì„¤ì • ì €ì¥"):
                # ì„¤ì • ì—…ë°ì´íŠ¸ ë¡œì§
                st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    def show_optimization(self):
        """ìµœì í™” í˜ì´ì§€"""
        st.header("íŒŒë¼ë¯¸í„° ìµœì í™”")

        col1, col2 = st.columns(2)

        with col1:
            model = st.selectbox(
                "ëª¨ë¸ ì„ íƒ",
                list(self.config_manager.model_configs.keys())
            )

            dataset = st.selectbox(
                "ë°ì´í„°ì…‹ ì„ íƒ",
                ["korean_math", "korean_qa", "korean_reasoning"]
            )

        with col2:
            strategy = st.selectbox(
                "ìµœì í™” ì „ëµ",
                ["grid_search", "bayesian"]
            )

            samples = st.slider("ìƒ˜í”Œ ìˆ˜", 10, 100, 20)

        safe_mode = st.checkbox("ì•ˆì „ ëª¨ë“œ", value=True)

        if st.button("ìµœì í™” ì‹œì‘"):
            with st.spinner("ìµœì í™” ì§„í–‰ ì¤‘..."):
                # ìµœì í™” ì‹¤í–‰ ë¡œì§ (ë¹„ë™ê¸°)
                st.success("ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                # ê²°ê³¼ í‘œì‹œ
                st.json({
                    "best_score": 0.85,
                    "best_params": {
                        "temperature": 0.1,
                        "top_p": 0.9,
                        "top_k": 50
                    }
                })

    def show_results(self):
        """ê²°ê³¼ ë¶„ì„ í˜ì´ì§€"""
        st.header("ê²°ê³¼ ë¶„ì„")

        # ê²°ê³¼ íŒŒì¼ ë¡œë“œ
        results_dir = Path("optimization_results")
        if results_dir.exists():
            files = list(results_dir.glob("*.json"))

            if files:
                selected_file = st.selectbox(
                    "ê²°ê³¼ íŒŒì¼ ì„ íƒ",
                    [f.name for f in files]
                )

                if selected_file:
                    file_path = results_dir / selected_file
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    # ê²°ê³¼ í‘œì‹œ
                    st.json(data)

                    # ì‹œê°í™”
                    if 'optimization_history' in data:
                        history = data['optimization_history']
                        scores = [h['score'] for h in history]

                        fig = go.Figure()
                        fig.add_trace(go.Scatter(
                            y=scores,
                            mode='lines+markers',
                            name='ìµœì í™” ì ìˆ˜'
                        ))

                        st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ì•„ì§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìµœì í™”ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            st.info("ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")


# CLIì— ì›¹ UI ëª…ë ¹ì–´ ì¶”ê°€
def add_web_ui_command(parser):
    """ì›¹ UI ëª…ë ¹ì–´ ì¶”ê°€"""
    web_parser = parser.add_parser('web', help='ì›¹ UI ì‹¤í–‰')
    web_parser.add_argument('--host', default='localhost', help='í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ')
    web_parser.add_argument('--port', type=int, default=8080, help='í¬íŠ¸ ë²ˆí˜¸')
    web_parser.add_argument('--auth', action='store_true', help='ì¸ì¦ í™œì„±í™”')


def run_web_command(args):
    """ì›¹ UI ì‹¤í–‰"""
    print(f"ğŸŒ ì›¹ UI ì‹œì‘: http://{args.host}:{args.port}")

    try:
        import streamlit
        print("âœ… Streamlit ê°ì§€ë¨")

        # ì›¹ UI ì‹¤í–‰
        ui = WebUI()
        ui.run()

    except ImportError:
        print("âŒ Streamlitì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install streamlit")
        print("ì‹¤í–‰: streamlit run web_ui.py")


# A/B í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥
class ABTestManager:
    """A/B í…ŒìŠ¤íŠ¸ ê´€ë¦¬ì"""

    def __init__(self):
        self.tests = {}
        self.results = {}

    def create_test(self, test_name: str, variant_a: dict, variant_b: dict):
        """A/B í…ŒìŠ¤íŠ¸ ìƒì„±"""
        self.tests[test_name] = {
            'variant_a': variant_a,
            'variant_b': variant_b,
            'status': 'created',
            'start_time': None,
            'end_time': None
        }

    def run_test(self, test_name: str, samples: List[str]):
        """A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if test_name not in self.tests:
            raise ValueError(f"Test {test_name} not found")

        test = self.tests[test_name]
        test['status'] = 'running'
        test['start_time'] = datetime.now()

        # ìƒ˜í”Œì„ ì ˆë°˜ì”© ë‚˜ëˆ„ì–´ ê° ë³€í˜•ì— í• ë‹¹
        mid = len(samples) // 2
        samples_a = samples[:mid]
        samples_b = samples[mid:]

        # ê° ë³€í˜•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results_a = self._run_variant(samples_a, test['variant_a'])
        results_b = self._run_variant(samples_b, test['variant_b'])

        # ê²°ê³¼ ì €ì¥
        self.results[test_name] = {
            'variant_a_results': results_a,
            'variant_b_results': results_b,
            'winner': 'a' if results_a['avg_score'] > results_b['avg_score'] else 'b',
            'confidence': self._calculate_confidence(results_a, results_b)
        }

        test['status'] = 'completed'
        test['end_time'] = datetime.now()

        return self.results[test_name]

    def _run_variant(self, samples: List[str], variant_params: dict):
        """ë³€í˜• í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•œ ì¶”ë¡  ì‹¤í–‰
        scores = [0.8 + (hash(s) % 100) / 500 for s in samples]  # ë”ë¯¸ ì ìˆ˜

        return {
            'samples_count': len(samples),
            'scores': scores,
            'avg_score': sum(scores) / len(scores),
            'std_score': np.std(scores),
            'params': variant_params
        }

    def _calculate_confidence(self, results_a: dict, results_b: dict) -> float:
        """í†µê³„ì  ì‹ ë¢°ë„ ê³„ì‚°"""
        # ê°„ë‹¨í•œ t-ê²€ì • ê¸°ë°˜ ì‹ ë¢°ë„
        from scipy import stats

        try:
            _, p_value = stats.ttest_ind(results_a['scores'], results_b['scores'])
            confidence = (1 - p_value) * 100
            return min(confidence, 99.9)
        except:
            return 50.0  # ê¸°ë³¸ê°’


# ìë™ ìŠ¤ì¼€ì¼ë§ ë§¤ë‹ˆì €
class AutoScalingManager:
    """ìë™ ìŠ¤ì¼€ì¼ë§ ê´€ë¦¬ì"""

    def __init__(self, min_replicas: int = 1, max_replicas: int = 10):
        self.min_replicas = min_replicas
        self.max_replicas = max_replicas
        self.current_replicas = 1
        self.metrics_history = []
        self.scaling_cooldown = 300  # 5ë¶„
        self.last_scale_time = 0

    def should_scale_up(self, current_load: float, avg_response_time: float) -> bool:
        """ìŠ¤ì¼€ì¼ ì—… í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        if time.time() - self.last_scale_time < self.scaling_cooldown:
            return False

        if self.current_replicas >= self.max_replicas:
            return False

        # ë¶€í•˜ê°€ 80% ì´ìƒì´ê±°ë‚˜ ì‘ë‹µì‹œê°„ì´ 5ì´ˆ ì´ìƒì¼ ë•Œ
        return current_load > 0.8 or avg_response_time > 5.0

    def should_scale_down(self, current_load: float, avg_response_time: float) -> bool:
        """ìŠ¤ì¼€ì¼ ë‹¤ìš´ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        if time.time() - self.last_scale_time < self.scaling_cooldown:
            return False

        if self.current_replicas <= self.min_replicas:
            return False

        # ë¶€í•˜ê°€ 30% ì´í•˜ì´ê³  ì‘ë‹µì‹œê°„ì´ 1ì´ˆ ì´í•˜ì¼ ë•Œ
        return current_load < 0.3 and avg_response_time < 1.0

    def scale_up(self):
        """ìŠ¤ì¼€ì¼ ì—… ì‹¤í–‰"""
        if self.current_replicas < self.max_replicas:
            self.current_replicas += 1
            self.last_scale_time = time.time()
            print(f"ğŸ“ˆ ìŠ¤ì¼€ì¼ ì—…: {self.current_replicas}ê°œ ì¸ìŠ¤í„´ìŠ¤")

    def scale_down(self):
        """ìŠ¤ì¼€ì¼ ë‹¤ìš´ ì‹¤í–‰"""
        if self.current_replicas > self.min_replicas:
            self.current_replicas -= 1
            self.last_scale_time = time.time()
            print(f"ğŸ“‰ ìŠ¤ì¼€ì¼ ë‹¤ìš´: {self.current_replicas}ê°œ ì¸ìŠ¤í„´ìŠ¤")


# í´ë¼ìš°ë“œ ë°°í¬ ë§¤ë‹ˆì €
class CloudDeploymentManager:
    """í´ë¼ìš°ë“œ ë°°í¬ ê´€ë¦¬ì"""

    def __init__(self, provider: str = "local"):
        self.provider = provider
        self.deployment_configs = {}
        self.active_deployments = {}

    def create_deployment_config(self, name: str, model_config: ModelConfig,
                                 instance_type: str = "auto", region: str = "auto"):
        """ë°°í¬ ì„¤ì • ìƒì„±"""
        self.deployment_configs[name] = {
            'model_config': model_config,
            'instance_type': instance_type,
            'region': region,
            'auto_scaling': True,
            'monitoring': True,
            'backup': True
        }

    def deploy(self, config_name: str) -> str:
        """ëª¨ë¸ ë°°í¬"""
        if config_name not in self.deployment_configs:
            raise ValueError(f"Deployment config {config_name} not found")

        config = self.deployment_configs[config_name]

        if self.provider == "local":
            return self._deploy_local(config_name, config)
        elif self.provider == "aws":
            return self._deploy_aws(config_name, config)
        elif self.provider == "gcp":
            return self._deploy_gcp(config_name, config)
        else:
            raise ValueError(f"Unsupported provider: {self.provider}")

    def _deploy_local(self, name: str, config: dict) -> str:
        """ë¡œì»¬ ë°°í¬"""
        deployment_id = f"local_{name}_{int(time.time())}"

        self.active_deployments[deployment_id] = {
            'name': name,
            'config': config,
            'status': 'running',
            'endpoint': f"http://localhost:8000/{name}",
            'start_time': datetime.now()
        }

        print(f"âœ… ë¡œì»¬ ë°°í¬ ì™„ë£Œ: {deployment_id}")
        return deployment_id

    def _deploy_aws(self, name: str, config: dict) -> str:
        """AWS ë°°í¬ (ë¯¸êµ¬í˜„)"""
        print("âš ï¸ AWS ë°°í¬ëŠ” v2.0ì—ì„œ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")
        return f"aws_{name}_pending"

    def _deploy_gcp(self, name: str, config: dict) -> str:
        """GCP ë°°í¬ (ë¯¸êµ¬í˜„)"""
        print("âš ï¸ GCP ë°°í¬ëŠ” v2.0ì—ì„œ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")
        return f"gcp_{name}_pending"

    def get_deployment_status(self, deployment_id: str) -> dict:
        """ë°°í¬ ìƒíƒœ ì¡°íšŒ"""
        if deployment_id in self.active_deployments:
            return self.active_deployments[deployment_id]
        else:
            return {'status': 'not_found'}

    def stop_deployment(self, deployment_id: str) -> bool:
        """ë°°í¬ ì¤‘ë‹¨"""
        if deployment_id in self.active_deployments:
            self.active_deployments[deployment_id]['status'] = 'stopped'
            print(f"â¹ï¸ ë°°í¬ ì¤‘ë‹¨: {deployment_id}")
            return True
        return False


# ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
class MonitoringSystem:
    """ì¢…í•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.alert_manager = AlertManager()
        self.dashboard_generator = DashboardGenerator()

    def start_monitoring(self, deployment_id: str):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.metrics_collector.start(deployment_id)
        print(f"ğŸ“Š ëª¨ë‹ˆí„°ë§ ì‹œì‘: {deployment_id}")

    def stop_monitoring(self, deployment_id: str):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨"""
        self.metrics_collector.stop(deployment_id)
        print(f"ğŸ“Š ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨: {deployment_id}")

    def get_real_time_metrics(self, deployment_id: str) -> dict:
        """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return self.metrics_collector.get_current_metrics(deployment_id)

    def generate_report(self, deployment_id: str, time_range: str = "1h") -> str:
        """ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ìƒì„±"""
        metrics = self.metrics_collector.get_historical_metrics(deployment_id, time_range)
        return self.dashboard_generator.create_report(metrics)


class MetricsCollector:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""

    def __init__(self):
        self.active_collectors = {}
        self.metrics_storage = {}

    def start(self, deployment_id: str):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        self.active_collectors[deployment_id] = True
        self.metrics_storage[deployment_id] = []

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        threading.Thread(
            target=self._collect_loop,
            args=(deployment_id,),
            daemon=True
        ).start()

    def stop(self, deployment_id: str):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ë‹¨"""
        self.active_collectors[deployment_id] = False

    def _collect_loop(self, deployment_id: str):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë£¨í”„"""
        while self.active_collectors.get(deployment_id, False):
            try:
                metrics = self._collect_current_metrics()
                self.metrics_storage[deployment_id].append({
                    'timestamp': datetime.now(),
                    'metrics': metrics
                })
                time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
            except Exception as e:
                print(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    def _collect_current_metrics(self) -> dict:
        """í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        import psutil

        metrics = {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'network_io': psutil.net_io_counters()._asdict(),
        }

        # GPU ë©”íŠ¸ë¦­ ì¶”ê°€
        try:
            import torch
            if torch.cuda.is_available():
                metrics['gpu_memory_used'] = torch.cuda.memory_allocated() / 1024 ** 3
                metrics['gpu_memory_total'] = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
        except:
            pass

        return metrics

    def get_current_metrics(self, deployment_id: str) -> dict:
        """í˜„ì¬ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        if deployment_id in self.metrics_storage and self.metrics_storage[deployment_id]:
            return self.metrics_storage[deployment_id][-1]['metrics']
        return {}

    def get_historical_metrics(self, deployment_id: str, time_range: str) -> list:
        """ê³¼ê±° ë©”íŠ¸ë¦­ ë°˜í™˜"""
        if deployment_id in self.metrics_storage:
            # ì‹œê°„ ë²”ìœ„ì— ë”°ë¥¸ í•„í„°ë§ (ê°„ë‹¨í•œ êµ¬í˜„)
            return self.metrics_storage[deployment_id][-100:]  # ìµœê·¼ 100ê°œ
        return []


class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬ì"""

    def __init__(self):
        self.alert_rules = []
        self.active_alerts = {}

    def add_rule(self, name: str, condition: callable, message: str, severity: str = "warning"):
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        self.alert_rules.append({
            'name': name,
            'condition': condition,
            'message': message,
            'severity': severity
        })

    def check_alerts(self, metrics: dict):
        """ì•Œë¦¼ ì¡°ê±´ í™•ì¸"""
        for rule in self.alert_rules:
            try:
                if rule['condition'](metrics):
                    self._trigger_alert(rule)
            except Exception as e:
                print(f"ì•Œë¦¼ ê·œì¹™ í™•ì¸ ì˜¤ë¥˜: {e}")

    def _trigger_alert(self, rule: dict):
        """ì•Œë¦¼ ë°œìƒ"""
        alert_id = f"{rule['name']}_{int(time.time())}"

        self.active_alerts[alert_id] = {
            'rule': rule,
            'triggered_at': datetime.now(),
            'status': 'active'
        }

        print(f"ğŸš¨ {rule['severity'].upper()} ì•Œë¦¼: {rule['message']}")


class DashboardGenerator:
    """ëŒ€ì‹œë³´ë“œ ìƒì„±ê¸°"""

    def create_report(self, metrics_history: list) -> str:
        """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
        if not metrics_history:
            return "<html><body><h1>ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤</h1></body></html>"

        # ìµœì‹  ë©”íŠ¸ë¦­
        latest = metrics_history[-1]['metrics']

        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .metric {{ display: inline-block; margin: 10px; padding: 15px; 
                         background: #f0f0f0; border-radius: 5px; }}
                .alert {{ background: #ffebee; border-left: 5px solid #f44336; }}
                .normal {{ background: #e8f5e8; border-left: 5px solid #4caf50; }}
            </style>
        </head>
        <body>
            <h1>ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</h1>
            <p>ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>

            <div class="metric {'alert' if latest.get('cpu_percent', 0) > 80 else 'normal'}">
                <h3>CPU ì‚¬ìš©ë¥ </h3>
                <p>{latest.get('cpu_percent', 0):.1f}%</p>
            </div>

            <div class="metric {'alert' if latest.get('memory_percent', 0) > 80 else 'normal'}">
                <h3>ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ </h3>
                <p>{latest.get('memory_percent', 0):.1f}%</p>
            </div>

            <div class="metric">
                <h3>GPU ë©”ëª¨ë¦¬</h3>
                <p>{latest.get('gpu_memory_used', 0):.1f}GB / {latest.get('gpu_memory_total', 0):.1f}GB</p>
            </div>

            <h2>ğŸ“ˆ ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬</h2>
            <p>ìˆ˜ì§‘ëœ ë°ì´í„° í¬ì¸íŠ¸: {len(metrics_history)}ê°œ</p>

        </body>
        </html>
        """

        return html


# í†µí•© ì‹œìŠ¤í…œ ë§¤ë‹ˆì €
class IntegratedSystemManager:
    """í†µí•© ì‹œìŠ¤í…œ ê´€ë¦¬ì"""

    def __init__(self):
        self.cloud_manager = CloudDeploymentManager()
        self.scaling_manager = AutoScalingManager()
        self.monitoring = MonitoringSystem()
        self.ab_testing = ABTestManager()

    def deploy_and_monitor(self, model_name: str, config: ModelConfig) -> str:
        """ëª¨ë¸ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        # ë°°í¬ ì„¤ì • ìƒì„±
        self.cloud_manager.create_deployment_config(
            model_name, config, "auto", "auto"
        )

        # ë°°í¬ ì‹¤í–‰
        deployment_id = self.cloud_manager.deploy(model_name)

        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.monitoring.start_monitoring(deployment_id)

        # ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •
        self.monitoring.alert_manager.add_rule(
            "high_cpu",
            lambda m: m.get('cpu_percent', 0) > 80,
            "CPU ì‚¬ìš©ë¥ ì´ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
            "warning"
        )

        self.monitoring.alert_manager.add_rule(
            "high_memory",
            lambda m: m.get('memory_percent', 0) > 85,
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ 85%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
            "critical"
        )

        print(f"ğŸš€ í†µí•© ë°°í¬ ì™„ë£Œ: {deployment_id}")
        return deployment_id

    def run_ab_test(self, test_name: str, variant_a: dict, variant_b: dict,
                    samples: List[str]) -> dict:
        """A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.ab_testing.create_test(test_name, variant_a, variant_b)
        results = self.ab_testing.run_test(test_name, samples)

        print(f"ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {test_name}")
        print(f"   ìŠ¹ì: ë³€í˜• {results['winner'].upper()}")
        print(f"   ì‹ ë¢°ë„: {results['confidence']:.1f}%")

        return results

    def get_system_status(self) -> dict:
        """ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            'active_deployments': len(self.cloud_manager.active_deployments),
            'running_tests': len([t for t in self.ab_testing.tests.values() if t['status'] == 'running']),
            'monitoring_active': len(self.monitoring.metrics_collector.active_collectors),
            'auto_scaling_enabled': True
        }


# CLIì— í†µí•© ëª…ë ¹ì–´ ì¶”ê°€ í•¨ìˆ˜ë“¤
def add_cloud_commands(subparsers):
    """í´ë¼ìš°ë“œ ê´€ë ¨ ëª…ë ¹ì–´ ì¶”ê°€"""

    # deploy ëª…ë ¹ì–´
    deploy_parser = subparsers.add_parser('deploy', help='ëª¨ë¸ í´ë¼ìš°ë“œ ë°°í¬')
    deploy_parser.add_argument('--model', required=True, help='ë°°í¬í•  ëª¨ë¸')
    deploy_parser.add_argument('--provider', choices=['local', 'aws', 'gcp'], default='local')
    deploy_parser.add_argument('--instance-type', default='auto')
    deploy_parser.add_argument('--region', default='auto')

    # monitor ëª…ë ¹ì–´
    monitor_parser = subparsers.add_parser('monitor', help='ëª¨ë‹ˆí„°ë§ ê´€ë¦¬')
    monitor_parser.add_argument('--deployment-id', required=True)
    monitor_parser.add_argument('--action', choices=['start', 'stop', 'status', 'report'])

    # ab-test ëª…ë ¹ì–´
    ab_parser = subparsers.add_parser('ab-test', help='A/B í…ŒìŠ¤íŠ¸')
    ab_parser.add_argument('--name', required=True, help='í…ŒìŠ¤íŠ¸ ì´ë¦„')
    ab_parser.add_argument('--variant-a', required=True, help='ë³€í˜• A ì„¤ì • íŒŒì¼')
    ab_parser.add_argument('--variant-b', required=True, help='ë³€í˜• B ì„¤ì • íŒŒì¼')
    ab_parser.add_argument('--samples', type=int, default=100, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')


def run_deploy_command(args):
    """ë°°í¬ ëª…ë ¹ì–´ ì‹¤í–‰"""
    print(f"ğŸš€ ëª¨ë¸ ë°°í¬ ì‹œì‘: {args.model}")

    try:
        config_manager = RobustConfigManager()
        model_config = config_manager.get_safe_model_config(args.model)

        if not model_config:
            print(f"âŒ ëª¨ë¸ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.model}")
            return

        manager = IntegratedSystemManager()
        manager.cloud_manager.provider = args.provider

        deployment_id = manager.deploy_and_monitor(args.model, model_config)

        print(f"âœ… ë°°í¬ ì™„ë£Œ!")
        print(f"   ë°°í¬ ID: {deployment_id}")
        print(f"   ì œê³µì: {args.provider}")
        print(f"   ëª¨ë‹ˆí„°ë§: í™œì„±í™”ë¨")

    except Exception as e:
        print(f"âŒ ë°°í¬ ì‹¤íŒ¨: {e}")


def run_monitor_command(args):
    """ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´ ì‹¤í–‰"""
    print(f"ğŸ“Š ëª¨ë‹ˆí„°ë§ ì‘ì—…: {args.action}")

    try:
        monitoring = MonitoringSystem()

        if args.action == 'start':
            monitoring.start_monitoring(args.deployment_id)
            print(f"âœ… ëª¨ë‹ˆí„°ë§ ì‹œì‘: {args.deployment_id}")

        elif args.action == 'stop':
            monitoring.stop_monitoring(args.deployment_id)
            print(f"â¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨: {args.deployment_id}")

        elif args.action == 'status':
            metrics = monitoring.get_real_time_metrics(args.deployment_id)
            print(f"ğŸ“ˆ í˜„ì¬ ìƒíƒœ:")
            for key, value in metrics.items():
                print(f"   {key}: {value}")

        elif args.action == 'report':
            report_path = monitoring.generate_report(args.deployment_id)
            print(f"ğŸ“„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_path}")

    except Exception as e:
        print(f"âŒ ëª¨ë‹ˆí„°ë§ ì‘ì—… ì‹¤íŒ¨: {e}")


def run_ab_test_command(args):
    """A/B í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ì‹¤í–‰"""
    print(f"ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ì‹œì‘: {args.name}")

    try:
        # ë³€í˜• ì„¤ì • ë¡œë“œ
        with open(args.variant_a, 'r') as f:
            variant_a = json.load(f)

        with open(args.variant_b, 'r') as f:
            variant_b = json.load(f)

        # í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìƒì„± (ë”ë¯¸)
        samples = [f"test_sample_{i}" for i in range(args.samples)]

        manager = IntegratedSystemManager()
        results = manager.run_ab_test(args.name, variant_a, variant_b, samples)

        print(f"âœ… A/B í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"   ë³€í˜• A ì ìˆ˜: {results['variant_a_results']['avg_score']:.3f}")
        print(f"   ë³€í˜• B ì ìˆ˜: {results['variant_b_results']['avg_score']:.3f}")
        print(f"   ìŠ¹ì: ë³€í˜• {results['winner'].upper()}")
        print(f"   í†µê³„ì  ì‹ ë¢°ë„: {results['confidence']:.1f}%")

    except Exception as e:
        print(f"âŒ A/B í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


# ë²„ì „ ì •ë³´
__version__ = "1.0.0"
__future_version__ = "2.0.0"

ROADMAP_FEATURES = {
    "v2.0": [
        "ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”",
        "ìë™ A/B í…ŒìŠ¤íŠ¸",
        "í´ë¼ìš°ë“œ ë°°í¬ ì§€ì›",
        "ì›¹ UI ì¸í„°í˜ì´ìŠ¤",
        "ë” ë§ì€ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì§€ì›"
    ],
    "v2.1": [
        "ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ ì„œì¹˜",
        "ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ",
        "ë³´ì•ˆ ë° ê°œì¸ì •ë³´ ë³´í˜¸ ê°•í™”",
        "ë‹¤ì¤‘ í´ëŸ¬ìŠ¤í„° ì§€ì›"
    ]
}


def show_roadmap():
    """ë¡œë“œë§µ í‘œì‹œ"""
    print("ğŸ”® ê°œë°œ ë¡œë“œë§µ:")
    for version, features in ROADMAP_FEATURES.items():
        print(f"\n{version} ê³„íš:")
        for feature in features:
            status = "ğŸš§" if version == "v2.0" else "ğŸ“‹"
            print(f"   {status} {feature}")


if __name__ == "__main__":
    print("ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
    print(f"ğŸ“¦ í˜„ì¬ ë²„ì „: {__version__}")
    print(f"ğŸ¯ ë‹¤ìŒ ë²„ì „: {__future_version__}")
    show_roadmap()