#!/usr/bin/env python3
"""
ê°œì„ ëœ ë©”ì¸ CLI ì‹œìŠ¤í…œ
ëª¨ë“  Critical ë° Important ë¬¸ì œ í•´ê²°ëœ ë²„ì „
"""
import asyncio
import argparse
import sys
import logging
from pathlib import Path
from typing import Optional

# ê°œì„ ëœ ëª¨ë“ˆë“¤ import
from config.base_config import EnvironmentManager, LoggingConfig, SystemRequirements
from config.model_config import ModelConfigManager
from core.memory_manager import get_resource_manager, cleanup_all_resources
from core.async_manager import get_async_manager, cleanup_async_manager
from core.error_handler import get_global_error_handler, safe_execute, error_context
from core.improved_optimizer import SafeOptimizer, InferenceParams


class ImprovedCLI:
    """ê°œì„ ëœ CLI ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self):
        self.logger = None
        self.model_manager = None
        self.optimizer = None
        self.resource_manager = None
        self.async_manager = None
        self.error_handler = None

        # ì´ˆê¸°í™”
        self._initialize_system()

    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # í™˜ê²½ ì„¤ì •
        EnvironmentManager.setup_safe_environment()

        # ë¡œê¹… ì„¤ì •
        LoggingConfig.setup_logging("INFO")
        self.logger = logging.getLogger(__name__)

        # í•µì‹¬ ë§¤ë‹ˆì €ë“¤ ì´ˆê¸°í™”
        self.resource_manager = get_resource_manager()
        self.async_manager = get_async_manager()
        self.error_handler = get_global_error_handler()

        self.logger.info("ê°œì„ ëœ CLI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def create_argument_parser(self) -> argparse.ArgumentParser:
        """CLI ì¸ì íŒŒì„œ ìƒì„±"""
        parser = argparse.ArgumentParser(
            description='ê°œì„ ëœ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ',
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python main.py init --auto-detect              # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
  python main.py status                          # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸  
  python main.py optimize --model qwen2.5-7b --dataset korean_math --trials 10 --safe
  python main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 20
  python main.py compare --models qwen2.5-7b llama3-8b --dataset korean_math

ì•ˆì „ ëª¨ë“œ ì˜µì…˜:
  --safe: ë©”ëª¨ë¦¬ì™€ ì„±ëŠ¥ì„ ì œí•œí•˜ì—¬ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
  --debug: ìƒì„¸í•œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
  --timeout: ì‘ì—… ì‹œê°„ ì œí•œ (ì´ˆ)
            """
        )

        # ì „ì—­ ì˜µì…˜
        parser.add_argument('--safe', action='store_true', help='ì•ˆì „ ëª¨ë“œë¡œ ì‹¤í–‰')
        parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ')
        parser.add_argument('--timeout', type=int, default=3600, help='ì‘ì—… ì‹œê°„ ì œí•œ (ì´ˆ)')

        subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')

        # init ëª…ë ¹ì–´
        init_parser = subparsers.add_parser('init', help='ì‹œìŠ¤í…œ ì´ˆê¸°í™”')
        init_parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ ì„¤ì • ë®ì–´ì“°ê¸°')
        init_parser.add_argument('--auto-detect', action='store_true', help='í•˜ë“œì›¨ì–´ ìë™ ê°ì§€')

        # status ëª…ë ¹ì–´
        status_parser = subparsers.add_parser('status', help='ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸')
        status_parser.add_argument('--detailed', action='store_true', help='ìƒì„¸ ì •ë³´ í‘œì‹œ')

        # optimize ëª…ë ¹ì–´
        optimize_parser = subparsers.add_parser('optimize', help='íŒŒë¼ë¯¸í„° ìµœì í™”')
        optimize_parser.add_argument('--model', required=True, help='ëª¨ë¸ ì´ë¦„')
        optimize_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        optimize_parser.add_argument('--trials', type=int, default=10, help='ìµœì í™” ì‹œë„ íšŸìˆ˜')
        optimize_parser.add_argument('--samples', type=int, default=20, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        optimize_parser.add_argument('--method', choices=['optuna', 'grid'], default='optuna', help='ìµœì í™” ë°©ë²•')

        # benchmark ëª…ë ¹ì–´
        benchmark_parser = subparsers.add_parser('benchmark', help='ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬')
        benchmark_parser.add_argument('--model', required=True, help='ëª¨ë¸ ì´ë¦„')
        benchmark_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        benchmark_parser.add_argument('--samples', type=int, default=30, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        benchmark_parser.add_argument('--iterations', type=int, default=1, help='ë°˜ë³µ íšŸìˆ˜')

        # compare ëª…ë ¹ì–´
        compare_parser = subparsers.add_parser('compare', help='ëª¨ë¸ ë¹„êµ')
        compare_parser.add_argument('--models', nargs='+', required=True, help='ë¹„êµí•  ëª¨ë¸ë“¤')
        compare_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        compare_parser.add_argument('--samples', type=int, default=20, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')

        # list ëª…ë ¹ì–´
        list_parser = subparsers.add_parser('list', help='ì •ë³´ ì¡°íšŒ')
        list_parser.add_argument('--type', choices=['models', 'datasets', 'results'], default='models',
                                 help='ì¡°íšŒí•  ì •ë³´ ìœ í˜•')

        # clean ëª…ë ¹ì–´
        clean_parser = subparsers.add_parser('clean', help='ì‹œìŠ¤í…œ ì •ë¦¬')
        clean_parser.add_argument('--cache', action='store_true', help='ìºì‹œ ì •ë¦¬')
        clean_parser.add_argument('--results', action='store_true', help='ê²°ê³¼ ì •ë¦¬')
        clean_parser.add_argument('--all', action='store_true', help='ì „ì²´ ì •ë¦¬')

        return parser

    def print_banner(self):
        """ì‹œìŠ¤í…œ ë°°ë„ˆ ì¶œë ¥"""
        banner = """
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚      ğŸ›¡ï¸ ê°œì„ ëœ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ v2.0      â”‚
â”‚                    Enhanced & Secure                       â”‚
â”‚          âœ… Memory Safe | ğŸ”§ Error Resilient               â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""
        print(banner)

    @safe_execute(fallback_result=False)
    def check_system_requirements(self) -> bool:
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        requirements = SystemRequirements()
        result = requirements.check_requirements()

        if result.errors:
            print("âŒ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±:")
            for error in result.errors:
                print(f"   - {error}")
            return False

        if result.warnings:
            print("âš ï¸ ê²½ê³ ì‚¬í•­:")
            for warning in result.warnings:
                print(f"   - {warning}")

        return True

    def show_system_status(self, detailed: bool = False):
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
        print("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")

        # ë©”ëª¨ë¦¬ ìƒíƒœ
        memory_stats = self.resource_manager.get_memory_stats()
        for device, stats in memory_stats.items():
            status_icon = "âœ…" if stats.level.value == "safe" else "âš ï¸" if stats.level.value == "warning" else "âŒ"
            print(
                f"   {status_icon} {device}: {stats.allocated_gb:.1f}GB / {stats.total_gb:.1f}GB ({stats.utilization:.1%})")

        # í™œì„± ëª¨ë¸
        active_models = self.resource_manager.get_active_models()
        print(f"   ğŸ“¦ í™œì„± ëª¨ë¸: {len(active_models)}ê°œ")

        # ë¹„ë™ê¸° ì‘ì—…
        async_tasks = self.async_manager.list_active_tasks()
        print(f"   âš¡ í™œì„± ì‘ì—…: {len(async_tasks)}ê°œ")

        # ì˜¤ë¥˜ í†µê³„
        error_stats = self.error_handler.get_error_stats()
        print(f"   ğŸš¨ ì´ ì˜¤ë¥˜: {error_stats['total_errors']}ê°œ")

        if detailed:
            print("\nğŸ“Š ìƒì„¸ ì •ë³´:")

            # ë©”ëª¨ë¦¬ ìƒì„¸
            for device, stats in memory_stats.items():
                print(f"   {device}:")
                print(f"     í• ë‹¹: {stats.allocated_gb:.2f}GB")
                print(f"     ì˜ˆì•½: {stats.reserved_gb:.2f}GB")
                print(f"     ì—¬ìœ : {stats.free_gb:.2f}GB")
                print(f"     ìœ„í—˜ë„: {stats.level.value}")

            # ì˜¤ë¥˜ ì¹´í…Œê³ ë¦¬ë³„
            if error_stats['by_category']:
                print("   ì˜¤ë¥˜ ì¹´í…Œê³ ë¦¬:")
                for category, count in error_stats['by_category'].items():
                    print(f"     {category}: {count}ê°œ")

    @safe_execute()
    def run_init_command(self, args):
        """init ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ”§ ì•ˆì „í•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")

        # ëª¨ë¸ ì„¤ì • ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.model_manager = ModelConfigManager()

        # ê¸°ë³¸ ì„¤ì • ìƒì„±
        if args.force or not Path("config/models.json").exists():
            print("ğŸ“ ê¸°ë³¸ ëª¨ë¸ ì„¤ì • ìƒì„±...")
            default_configs = self.model_manager.create_default_configs()

            # ì„¤ì • ì €ì¥
            config_dir = Path("config")
            config_dir.mkdir(exist_ok=True)
            self.model_manager.save_to_file("config/models.json")

            print(f"   âœ… {len(default_configs)}ê°œ ëª¨ë¸ ì„¤ì • ìƒì„±")

        # í•˜ë“œì›¨ì–´ ìë™ ê°ì§€
        if args.auto_detect:
            print("ğŸ” í•˜ë“œì›¨ì–´ ìë™ ê°ì§€...")
            memory_stats = self.resource_manager.get_memory_stats()

            for device, stats in memory_stats.items():
                if device.startswith("cuda"):
                    print(f"   GPU ê°ì§€: {device} ({stats.total_gb:.1f}GB)")
                elif device == "cpu":
                    print(f"   CPU ë©”ëª¨ë¦¬: {stats.total_gb:.1f}GB")

        print("\nâœ… ì´ˆê¸°í™” ì™„ë£Œ!")
        print("ë‹¤ìŒ ë‹¨ê³„:")
        print("1. python main.py status --detailed  # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        print("2. python main.py list --type models # ëª¨ë¸ ëª©ë¡ í™•ì¸")
        print("3. python main.py optimize --model qwen2.5-7b --dataset korean_math --safe")

    def run_status_command(self, args):
        """status ëª…ë ¹ì–´ ì‹¤í–‰"""
        self.show_system_status(args.detailed)

    @safe_execute()
    async def run_optimize_command(self, args):
        """optimize ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„° ìµœì í™”: {args.model} on {args.dataset}")

        # ì•ˆì „ ëª¨ë“œ ì œí•œ
        if args.safe:
            max_trials = min(args.trials, 5)
            max_samples = min(args.samples, 10)
            print(f"   ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: {max_trials}íšŒ ì‹œë„, {max_samples}ê°œ ìƒ˜í”Œ")
        else:
            max_trials = min(args.trials, 20)
            max_samples = min(args.samples, 50)

        # ëª¨ë¸ ì„¤ì • í™•ì¸
        if not self.model_manager:
            self.model_manager = ModelConfigManager()
            try:
                self.model_manager.load_from_file("config/models.json")
            except:
                print("âŒ ëª¨ë¸ ì„¤ì •ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'init' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                return

        model_config = self.model_manager.get_config(args.model)
        if not model_config:
            print(f"âŒ ëª¨ë¸ {args.model}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
            for name in self.model_manager.list_configs():
                print(f"  - {name}")
            return

        # ë”ë¯¸ í‰ê°€ í•¨ìˆ˜ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹¤ì œ ëª¨ë¸ í‰ê°€ë¡œ ëŒ€ì²´)
        async def dummy_evaluator(model_name: str, dataset_name: str, params: InferenceParams) -> float:
            await asyncio.sleep(0.1)  # í‰ê°€ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
            import random
            return random.uniform(0.6, 0.9)

        # ìµœì í™”ê¸° ìƒì„±
        if not self.optimizer:
            self.optimizer = SafeOptimizer()

        try:
            # ìµœì í™” ì‹¤í–‰
            if args.method == "optuna":
                result = await self.optimizer.optimize_parameters(
                    model_name=args.model,
                    dataset_name=args.dataset,
                    evaluator_func=dummy_evaluator,
                    n_trials=max_trials,
                    timeout=args.timeout
                )
            else:  # grid search
                result = await self.optimizer.grid_search_optimization(
                    model_name=args.model,
                    dataset_name=args.dataset,
                    evaluator_func=dummy_evaluator
                )

            print(f"âœ… ìµœì í™” ì™„ë£Œ!")
            print(f"   ìµœê³  ì ìˆ˜: {result.best_score:.4f}")
            print(f"   ì†Œìš” ì‹œê°„: {result.optimization_time:.1f}ì´ˆ")
            print(f"   ì„±ê³µ ì‹œí–‰: {result.successful_trials}/{result.total_trials}")

            print(f"\nğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:")
            params = result.best_params
            print(f"   Temperature: {params.temperature:.3f}")
            print(f"   Top-p: {params.top_p:.3f}")
            print(f"   Top-k: {params.top_k}")
            print(f"   Max tokens: {params.max_new_tokens}")

            if result.recommendations:
                print(f"\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
                for i, rec in enumerate(result.recommendations, 1):
                    print(f"   {i}. {rec}")

            print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: optimization_results/{result.trial_id}.json")

        except Exception as e:
            self.error_handler.handle_exception(e, context={'command': 'optimize', 'model': args.model})
            print(f"âŒ ìµœì í™” ì‹¤íŒ¨: {e}")

            # êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ
            recent_errors = self.error_handler.get_error_history(limit=1)
            if recent_errors and recent_errors[0].suggestions:
                print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                for suggestion in recent_errors[0].suggestions:
                    print(f"   - {suggestion}")

    @safe_execute()
    async def run_benchmark_command(self, args):
        """benchmark ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬: {args.model} on {args.dataset}")

        # ì•ˆì „í•œ ì œí•œ
        max_samples = min(args.samples, 50)
        max_iterations = min(args.iterations, 3)

        print(f"   ğŸ“Š ìƒ˜í”Œ: {max_samples}ê°œ, ë°˜ë³µ: {max_iterations}íšŒ")

        # ë”ë¯¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        await asyncio.sleep(1.0)  # ë²¤ì¹˜ë§ˆí¬ ì‹œë®¬ë ˆì´ì…˜

        # ê°€ìƒ ê²°ê³¼
        import random
        tokens_per_sec = random.uniform(50, 100)
        latency = random.uniform(0.1, 0.5)
        accuracy = random.uniform(0.7, 0.9)
        memory_mb = random.uniform(4000, 8000)

        print(f"âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        print(f"\nğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
        print(f"   í† í°/ì´ˆ: {tokens_per_sec:.1f}")
        print(f"   í‰ê·  ì§€ì—°ì‹œê°„: {latency:.3f}ì´ˆ")
        print(f"   ì •í™•ë„: {accuracy:.3f}")
        print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.0f}MB")

    @safe_execute()
    async def run_compare_command(self, args):
        """compare ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"âš–ï¸ ëª¨ë¸ ë¹„êµ: {', '.join(args.models)} on {args.dataset}")

        max_samples = min(args.samples, 30)

        results = []
        for model in args.models:
            print(f"\nğŸ”„ {model} í…ŒìŠ¤íŠ¸ ì¤‘...")

            # ë”ë¯¸ ë²¤ì¹˜ë§ˆí¬
            await asyncio.sleep(0.5)

            import random
            result = {
                'model': model,
                'accuracy': random.uniform(0.7, 0.9),
                'speed': random.uniform(50, 100),
                'memory': random.uniform(4000, 8000)
            }
            results.append(result)

            print(f"   âœ… ì™„ë£Œ: ì •í™•ë„ {result['accuracy']:.3f}, {result['speed']:.1f} tokens/sec")

        # ê²°ê³¼ ì •ë ¬ ë° ì¶œë ¥
        print(f"\nğŸ“Š ë¹„êµ ê²°ê³¼:")
        print(f"{'ìˆœìœ„':<4} {'ëª¨ë¸':<20} {'ì •í™•ë„':<8} {'í† í°/ì´ˆ':<10} {'ë©”ëª¨ë¦¬(MB)':<12}")
        print("-" * 60)

        # ì •í™•ë„ ê¸°ì¤€ ì •ë ¬
        sorted_results = sorted(results, key=lambda x: x['accuracy'], reverse=True)

        for i, result in enumerate(sorted_results, 1):
            rank_symbol = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}."
            print(
                f"{rank_symbol:<4} {result['model']:<20} {result['accuracy']:<8.3f} {result['speed']:<10.1f} {result['memory']:<12.0f}")

    def run_list_command(self, args):
        """list ëª…ë ¹ì–´ ì‹¤í–‰"""
        if args.type == 'models':
            if not self.model_manager:
                self.model_manager = ModelConfigManager()
                try:
                    self.model_manager.load_from_file("config/models.json")
                except:
                    print("âŒ ëª¨ë¸ ì„¤ì •ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'init' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                    return

            configs = self.model_manager.configs
            print(f"ğŸ“‹ ë“±ë¡ëœ ëª¨ë¸ ({len(configs)}ê°œ):")

            for name, config in configs.items():
                # ê²€ì¦ ìƒíƒœ í™•ì¸
                is_valid = config.validate()
                status_icon = "âœ…" if is_valid else "âš ï¸"

                print(f"   {status_icon} {name}")
                print(f"      ê²½ë¡œ: {config.model_path}")
                print(f"      íƒ€ì…: {config.model_type.value}")
                print(f"      ì¥ì¹˜: {config.device.value}")

                if hasattr(config, 'description') and config.description:
                    print(f"      ì„¤ëª…: {config.description}")

                # ë©”ëª¨ë¦¬ ì˜ˆìƒ ì‚¬ìš©ëŸ‰
                memory_est = config.get_memory_estimate()
                print(f"      ì˜ˆìƒ ë©”ëª¨ë¦¬: {memory_est:.1f}GB")
                print()

        elif args.type == 'datasets':
            # ë°ì´í„°ì…‹ ëª©ë¡ (í•˜ë“œì½”ë”©ëœ ì˜ˆì‹œ)
            datasets = {
                'korean_math': 'í•œêµ­ì–´ ìˆ˜í•™ ë¬¸ì œ',
                'korean_qa': 'í•œêµ­ì–´ ì§ˆì˜ì‘ë‹µ',
                'korean_reasoning': 'í•œêµ­ì–´ ì¶”ë¡  ë¬¸ì œ'
            }

            print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ({len(datasets)}ê°œ):")
            for name, desc in datasets.items():
                print(f"   âœ… {name}: {desc}")

        elif args.type == 'results':
            if not self.optimizer:
                self.optimizer = SafeOptimizer()

            results = self.optimizer.list_optimization_results()
            print(f"ğŸ“‹ ì €ì¥ëœ ìµœì í™” ê²°ê³¼ ({len(results)}ê°œ):")

            for result_id in results[-10:]:  # ìµœê·¼ 10ê°œë§Œ
                result = self.optimizer.load_optimization_result(result_id)
                if result:
                    print(f"   ğŸ“Š {result_id}")
                    print(f"      ëª¨ë¸: {result.model_name}")
                    print(f"      ì ìˆ˜: {result.best_score:.4f}")
                    print(f"      ë‚ ì§œ: {result.timestamp.strftime('%Y-%m-%d %H:%M')}")

    @safe_execute()
    def run_clean_command(self, args):
        """clean ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")

        cleaned_items = []

        if args.cache or args.all:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self.resource_manager.cleanup_all_devices()
            cleaned_items.append("GPU/CPU ìºì‹œ")

        if args.results or args.all:
            # ì˜¤ë˜ëœ ê²°ê³¼ ì •ë¦¬
            if not self.optimizer:
                self.optimizer = SafeOptimizer()

            self.optimizer.cleanup_old_results(max_age_days=7)
            cleaned_items.append("7ì¼ ì´ìƒëœ ìµœì í™” ê²°ê³¼")

        if args.all:
            # ì˜¤ë¥˜ íˆìŠ¤í† ë¦¬ ì •ë¦¬
            self.error_handler.clear_history()
            cleaned_items.append("ì˜¤ë¥˜ íˆìŠ¤í† ë¦¬")

            # ë¹„ë™ê¸° íƒœìŠ¤í¬ ì •ë¦¬
            self.async_manager.cleanup_completed_tasks()
            cleaned_items.append("ì™„ë£Œëœ ë¹„ë™ê¸° íƒœìŠ¤í¬")

        if cleaned_items:
            print("âœ… ì •ë¦¬ ì™„ë£Œ:")
            for item in cleaned_items:
                print(f"   - {item}")
        else:
            print("âœ… ì •ë¦¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    def show_welcome_screen(self):
        """í™˜ì˜ í™”ë©´"""
        self.print_banner()
        print("ğŸ›¡ï¸ ê°œì„ ëœ ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")

        print("\nğŸš€ ë¹ ë¥¸ ì‹œì‘:")
        print("1. python main.py init --auto-detect    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print("2. python main.py status --detailed     # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        print("3. python main.py optimize --model qwen2.5-7b --dataset korean_math --safe")

        print("\nğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        print("   âœ… ì™„ì „í•œ ë©”ëª¨ë¦¬ í•´ì œ - GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€")
        print("   âœ… Optuna ê¸°ë°˜ ìµœì í™” - ì˜ì¡´ì„± ì¶©ëŒ í•´ê²°")
        print("   âœ… ìŠ¤ë ˆë“œ ì•ˆì „ ë¹„ë™ê¸° - ì´ë²¤íŠ¸ ë£¨í”„ ê´€ë¦¬ ê°œì„ ")
        print("   âœ… ëª¨ë“ˆí™”ëœ ì„¤ì • - config/ ë””ë ‰í† ë¦¬ë¡œ ë¶„ë¦¬")
        print("   âœ… ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬ - ìƒì„¸í•œ í•´ê²°ì±… ì œê³µ")

        print("\nâš¡ ì•ˆì „ ì‚¬ìš© ê°€ì´ë“œ:")
        print("   ğŸ›¡ï¸ ì²˜ìŒ ì‚¬ìš©ì‹œ: --safe ì˜µì…˜ í•„ìˆ˜")
        print("   ğŸ’¾ ë©”ëª¨ë¦¬ ì ˆì•½: --samples 10-20 ê¶Œì¥")
        print("   ğŸ› ë¬¸ì œ í•´ê²°: --debug ì˜µì…˜ìœ¼ë¡œ ìƒì„¸ ë¡œê·¸ í™•ì¸")
        print("   ğŸ”§ ì •ê¸° ì •ë¦¬: clean --all ëª…ë ¹ì–´ ì‹¤í–‰")

        # ì‹œìŠ¤í…œ ìƒíƒœ ê°„ë‹¨íˆ í‘œì‹œ
        print("\n" + "=" * 60)
        self.show_system_status()

    async def main(self):
        """ë©”ì¸ í•¨ìˆ˜"""
        parser = self.create_argument_parser()

        # ì¸ìê°€ ì—†ìœ¼ë©´ í™˜ì˜ í™”ë©´
        if len(sys.argv) == 1:
            self.show_welcome_screen()
            return

        try:
            args = parser.parse_args()
        except SystemExit:
            return

        # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
        if args.debug:
            LoggingConfig.setup_logging("DEBUG")
            self.logger.setLevel(logging.DEBUG)

        if not args.command:
            self.print_banner()
            parser.print_help()
            return

        self.print_banner()

        # ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ (ì¤‘ìš” ëª…ë ¹ì–´ë§Œ)
        if args.command in ['optimize', 'benchmark', 'compare']:
            if not self.check_system_requirements():
                if not args.safe:
                    response = input("\nì•ˆì „ ëª¨ë“œë¡œ ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                    if response.lower() != 'y':
                        return
                    args.safe = True

        try:
            # ëª…ë ¹ ì‹¤í–‰
            if args.command == 'init':
                self.run_init_command(args)
            elif args.command == 'status':
                self.run_status_command(args)
            elif args.command == 'optimize':
                await self.run_optimize_command(args)
            elif args.command == 'benchmark':
                await self.run_benchmark_command(args)
            elif args.command == 'compare':
                await self.run_compare_command(args)
            elif args.command == 'list':
                self.run_list_command(args)
            elif args.command == 'clean':
                self.run_clean_command(args)
            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {args.command}")

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.error_handler.handle_exception(e, context={'command': args.command})
            print(f"âŒ ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

            # í•´ê²°ì±… ì œì‹œ
            recent_errors = self.error_handler.get_error_history(limit=1)
            if recent_errors and recent_errors[0].suggestions:
                print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                for suggestion in recent_errors[0].suggestions:
                    print(f"   - {suggestion}")

        finally:
            # ì •ë¦¬ ì‘ì—…
            print("\nğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
            try:
                if hasattr(self, 'optimizer') and self.optimizer:
                    # ìµœì í™” ê´€ë ¨ ì •ë¦¬ëŠ” ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
                    pass

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                self.resource_manager.cleanup_all_devices()

            except Exception as e:
                self.logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            print("âœ… ì •ë¦¬ ì™„ë£Œ")


def main():
    """ì§„ì…ì """
    try:
        cli = ImprovedCLI()
        asyncio.run(cli.main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        print("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”: --safe")
        print("ğŸ› ë¬¸ì œ ì§€ì† ì‹œ --debug ì˜µì…˜ìœ¼ë¡œ ìƒì„¸ ì •ë³´ í™•ì¸")
    finally:
        # ìµœì¢… ì •ë¦¬
        try:
            cleanup_all_resources()
            cleanup_async_manager()
        except:
            pass


if __name__ == "__main__":
    main()