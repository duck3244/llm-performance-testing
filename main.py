class SafeCLI:
    """ì•ˆì „í•œ CLI ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self):
        self.logger = None
        self.config_manager = None
        self.optimizer = None
        self._initialized = False

    def _ensure_imports(self):
        """í•„ìš”í•œ ëª¨ë“ˆë“¤ì´ importë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        if not IMPORTS_OK:
            print(f"âŒ {IMPORT_ERROR}")
            print("\nğŸ“¦ ëˆ„ë½ëœ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
            print("   pip install torch transformers numpy pandas optuna")
            print("\nğŸ“ í•„ìš”í•œ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”:")
            print("   - safe_config.py")
            print("   - safe_model_interface.py")
            print("   - safe_optimizer.py")
            print("   - dataset_loader.py")
            sys.exit(1)

    def _initialize(self):
        """CLI ì´ˆê¸°í™”"""
        if self._initialized:
            return

        self._ensure_imports()

        # ì´ì œ ì•ˆì „í•˜ê²Œ import ê°€ëŠ¥
        global ConfigManager, HardwareDetector, SafeOptimizer
        from config import ConfigManager, HardwareDetector
        from optimizer import SafeOptimizer

        self.logger = logging.getLogger(__name__)
        self._initialized = True

    def create_argument_parser(self) -> argparse.ArgumentParser:
        """CLI ì¸ì íŒŒì„œ ìƒì„±"""
        parser = argparse.ArgumentParser(
            description='ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ',
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ì•ˆì „í•œ ì‚¬ìš© ì˜ˆì‹œ:
  python safe_main.py init --auto-detect              # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
  python safe_main.py hardware                        # í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸
  python safe_main.py optimize --model qwen2.5-7b --dataset korean_math --samples 20 --safe
  python safe_main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 30
  python safe_main.py compare --models qwen2.5-7b llama2-7b --dataset korean_math
  python safe_main.py status                          # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

ì•ˆì „ ëª¨ë“œ ì˜µì…˜:
  --safe: ë©”ëª¨ë¦¬ì™€ ì„±ëŠ¥ì„ ì œí•œí•˜ì—¬ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
  --debug: ìƒì„¸í•œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
  --timeout: ì‘ì—… ì‹œê°„ ì œí•œ (ì´ˆ)
            """
        )

        # ì „ì—­ ì˜µì…˜
        parser.add_argument('--safe', action='store_true', help='ì•ˆì „ ëª¨ë“œë¡œ ì‹¤í–‰')
        parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ')
        parser.add_argument('--timeout', type=int, default=3600, help='ì‘ì—… ì‹œê°„ ì œí•œ (ì´ˆ)')

        subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')

        # init ëª…ë ¹ì–´
        init_parser = subparsers.add_parser('init', help='ì‹œìŠ¤í…œ ì´ˆê¸°í™”')
        init_parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ ì„¤ì • ë®ì–´ì“°ê¸°')
        init_parser.add_argument('--auto-detect', action='store_true', help='í•˜ë“œì›¨ì–´ ìë™ ê°ì§€')

        # hardware ëª…ë ¹ì–´
        hardware_parser = subparsers.add_parser('hardware', help='í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸')
        hardware_parser.add_argument('--model-size', choices=['1b', '3b', '7b', '13b', '30b', '70b'],
                                     help='ëª¨ë¸ í¬ê¸°ë³„ ì¶”ì²œ')

        # optimize ëª…ë ¹ì–´
        optimize_parser = subparsers.add_parser('optimize', help='íŒŒë¼ë¯¸í„° ìµœì í™”')
        optimize_parser.add_argument('--model', required=True, help='ëª¨ë¸ ì´ë¦„')
        optimize_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        optimize_parser.add_argument('--strategy', choices=['optuna', 'grid_search'],
                                     default='grid_search', help='ìµœì í™” ì „ëµ')
        optimize_parser.add_argument('--trials', type=int, default=10, help='ìµœì í™” ì‹œë„ íšŸìˆ˜')
        optimize_parser.add_argument('--samples', type=int, default=20, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        optimize_parser.add_argument('--evaluator', choices=['exact_match', 'contains', 'similarity'],
                                     default='similarity', help='í‰ê°€ì ìœ í˜•')

        # benchmark ëª…ë ¹ì–´
        benchmark_parser = subparsers.add_parser('benchmark', help='ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬')
        benchmark_parser.add_argument('--model', required=True, help='ëª¨ë¸ ì´ë¦„')
        benchmark_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        benchmark_parser.add_argument('--samples', type=int, default=30, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        benchmark_parser.add_argument('--iterations', type=int, default=1, help='ë°˜ë³µ íšŸìˆ˜')
        benchmark_parser.add_argument('--temperature', type=float, default=0.1, help='Temperature')
        benchmark_parser.add_argument('--top-p', type=float, default=0.9, help='Top-p')
        benchmark_parser.add_argument('--max-tokens', type=int, default=200, help='ìµœëŒ€ í† í° ìˆ˜')

        # compare ëª…ë ¹ì–´
        compare_parser = subparsers.add_parser('compare', help='ëª¨ë¸ ë¹„êµ')
        compare_parser.add_argument('--models', nargs='+', required=True, help='ë¹„êµí•  ëª¨ë¸ë“¤')
        compare_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        compare_parser.add_argument('--samples', type=int, default=20, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        compare_parser.add_argument('--metric', choices=['accuracy', 'speed', 'efficiency'],
                                    default='accuracy', help='ë¹„êµ ê¸°ì¤€')

        # list ëª…ë ¹ì–´
        list_parser = subparsers.add_parser('list', help='ì •ë³´ ì¡°íšŒ')
        list_parser.add_argument('--type', choices=['models', 'datasets', 'results'],
                                 default='models', help='ì¡°íšŒí•  ì •ë³´ ìœ í˜•')

        # status ëª…ë ¹ì–´
        status_parser = subparsers.add_parser('status', help='ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸')

        # clean ëª…ë ¹ì–´
        clean_parser = subparsers.add_parser('clean', help='ì‹œìŠ¤í…œ ì •ë¦¬')
        clean_parser.add_argument('--cache', action='store_true', help='ìºì‹œ ì •ë¦¬')
        clean_parser.add_argument('--logs', action='store_true', help='ë¡œê·¸ ì •ë¦¬')
        clean_parser.add_argument('--results', action='store_true', help='ê²°ê³¼ ì •ë¦¬')
        clean_parser.add_argument('--all', action='store_true', help='ëª¨ë“  ì •ë¦¬')

        return parser

    def print_banner(self):
        """ì‹œìŠ¤í…œ ë°°ë„ˆ ì¶œë ¥"""
        banner = """
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚          ğŸ›¡ï¸ ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ         â”‚
â”‚              Safe Open Source LLM Optimizer               â”‚
â”‚                    âœ… Security Enhanced                    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""
        print(banner)

    def check_system_requirements(self) -> bool:
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        requirements_met = True
        issues = []

        # Python ë²„ì „ í™•ì¸
        if sys.version_info < (3, 8):
            issues.append(f"Python 3.8+ í•„ìš” (í˜„ì¬: {sys.version})")
            requirements_met = False

        # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
        required_packages = {
            'torch': 'PyTorch',
            'transformers': 'HuggingFace Transformers',
            'numpy': 'NumPy',
            'psutil': 'psutil'
        }

        missing_packages = []
        for package, description in required_packages.items():
            try:
                __import__(package)
            except ImportError:
                missing_packages.append(f"{package} ({description})")

        if missing_packages:
            issues.append(f"ëˆ„ë½ëœ í•„ìˆ˜ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
            requirements_met = False

        # ì„ íƒì  íŒ¨í‚¤ì§€ í™•ì¸
        optional_packages = {
            'optuna': 'Optuna (ê³ ê¸‰ ìµœì í™”ìš©)',
            'plotly': 'Plotly (ì‹œê°í™”ìš©)'
        }

        missing_optional = []
        for package, description in optional_packages.items():
            try:
                __import__(package)
            except ImportError:
                missing_optional.append(f"{package} ({description})")

        if missing_optional:
            print(f"âš ï¸ ì„ íƒì  íŒ¨í‚¤ì§€ ëˆ„ë½: {', '.join(missing_optional)}")
            print("  ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # í•˜ë“œì›¨ì–´ ì •ë³´
        try:
            if IMPORTS_OK:
                hardware_info = HardwareDetector.detect_hardware()
                if hardware_info['cuda_available']:
                    gpu_count = hardware_info['cuda_device_count']
                    total_memory = sum(
                        hardware_info.get(f'gpu_{i}_memory', 0)
                        for i in range(gpu_count)
                    )
                    print(f"âœ… GPU ê°ì§€: {gpu_count}ê°œ, ì´ ë©”ëª¨ë¦¬: {total_memory}GB")
                else:
                    print("âš ï¸ CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ë¶ˆê°€: {e}")

        # ì˜¤ë¥˜ ì¶œë ¥
        if issues:
            print(f"âŒ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±:")
            for issue in issues:
                print(f"   - {issue}")

            print(f"\nğŸ’¡ í•´ê²° ë°©ë²•:")
            if missing_packages:
                packages = [p.split(' ')[0] for p in missing_packages]
                print(f"   pip install {' '.join(packages)}")

        return requirements_met

    def show_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
        print("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")

        # ì„¤ì • íŒŒì¼ í™•ì¸
        config_file = Path("llm_config.json")
        if config_file.exists():
            try:
                if not self.config_manager:
                    self.config_manager = ConfigManager()
                model_count = len(self.config_manager.model_configs)
                print(f"   âœ… ì„¤ì • íŒŒì¼: {model_count}ê°œ ëª¨ë¸ ë“±ë¡ë¨")

                # ì„¤ì • ê²€ì¦
                validation_results = self.config_manager.validate_all_configs()
                if validation_results:
                    print(f"   âš ï¸ ì„¤ì • ë¬¸ì œ: {len(validation_results)}ê°œ ëª¨ë¸ì—ì„œ ê²½ê³ ")
                else:
                    print("   âœ… ëª¨ë“  ì„¤ì •ì´ ì•ˆì „í•©ë‹ˆë‹¤")

            except Exception as e:
                print(f"   âŒ ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        else:
            print("   âŒ ì„¤ì • íŒŒì¼ ì—†ìŒ (init ëª…ë ¹ ì‹¤í–‰ í•„ìš”)")

        # ë””ë ‰í† ë¦¬ í™•ì¸
        directories = {
            "data": "ë°ì´í„°ì…‹",
            "optimization_results": "ìµœì í™” ê²°ê³¼",
            "logs": "ë¡œê·¸ íŒŒì¼"
        }

        for dir_name, description in directories.items():
            dir_path = Path(dir_name)
            if dir_path.exists():
                file_count = len(list(dir_path.glob("*")))
                print(f"   âœ… {description}: {file_count}ê°œ íŒŒì¼")
            else:
                print(f"   âŒ {description} ë””ë ‰í† ë¦¬ ì—†ìŒ")

        # í•˜ë“œì›¨ì–´ ì •ë³´ (IMPORTS_OKì¼ ë•Œë§Œ)
        if IMPORTS_OK:
            try:
                hardware_info = HardwareDetector.detect_hardware()
                print(f"   ğŸ’» ì‹œìŠ¤í…œ:")
                print(f"      CPU: {hardware_info['cpu_cores']}ì½”ì–´")
                print(f"      ë©”ëª¨ë¦¬: {hardware_info['available_memory']}/{hardware_info['total_memory']}GB")

                if hardware_info['cuda_available']:
                    for i in range(hardware_info['cuda_device_count']):
                        gpu_name = hardware_info.get(f'gpu_{i}_name', f'GPU {i}')
                        gpu_memory = hardware_info.get(f'gpu_{i}_memory', 0)
                        print(f"      {gpu_name}: {gpu_memory}GB")
                else:
                    print(f"      GPU: ì‚¬ìš© ë¶ˆê°€")

            except Exception as e:
                print(f"   âš ï¸ í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ë¶ˆê°€: {e}")

    def run_init_command(self, args):
        """init ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ”§ ì•ˆì „í•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self._initialize()

        config_file = Path("llm_config.json")

        if config_file.exists() and not args.force:
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {config_file}")
            print("   ë®ì–´ì“°ë ¤ë©´ --force ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return

        try:
            # ì„¤ì • ë§¤ë‹ˆì € ìƒì„±
            self.config_manager = ConfigManager()
            print(f"âœ… ì•ˆì „í•œ ì„¤ì • íŒŒì¼ ìƒì„±: {config_file}")

            # ë””ë ‰í† ë¦¬ ìƒì„±
            directories = ["data", "optimization_results", "logs"]
            for directory in directories:
                Path(directory).mkdir(exist_ok=True)
                print(f"   âœ… {directory} ë””ë ‰í† ë¦¬ ìƒì„±")

            # í•˜ë“œì›¨ì–´ ìë™ ê°ì§€
            if args.auto_detect:
                print("ğŸ” í•˜ë“œì›¨ì–´ ìë™ ê°ì§€...")
                hardware_info = HardwareDetector.detect_hardware()
                print(f"   GPU: {hardware_info['cuda_device_count']}ê°œ")
                print(f"   ë©”ëª¨ë¦¬: {hardware_info['total_memory']}GB")

                if hardware_info['cuda_available']:
                    total_gpu_memory = sum(
                        hardware_info.get(f'gpu_{i}_memory', 0)
                        for i in range(hardware_info['cuda_device_count'])
                    )
                    print(f"   GPU ë©”ëª¨ë¦¬: {total_gpu_memory}GB")

            print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
            print("1. í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸: python safe_main.py hardware")
            print("2. ëª¨ë¸ ëª©ë¡ í™•ì¸: python safe_main.py list --type models")
            print(
                "3. ì•ˆì „í•œ ìµœì í™” ì‹¤í–‰: python safe_main.py optimize --model qwen2.5-7b --dataset korean_math --samples 10 --safe")

        except Exception as e:
            if self.logger:
                self.logger.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            if args.debug:
                traceback.print_exc()

    def run_hardware_command(self, args):
        """hardware ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ’» í•˜ë“œì›¨ì–´ ì •ë³´ ë¶„ì„")
        self._initialize()

        try:
            hardware_info = HardwareDetector.detect_hardware()

            print(f"\nğŸ” ê°ì§€ëœ í•˜ë“œì›¨ì–´:")
            print(f"   í”Œë«í¼: {hardware_info['platform']}")
            print(f"   CUDA ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if hardware_info['cuda_available'] else 'âŒ'}")
            print(f"   MPS ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if hardware_info.get('mps_available', False) else 'âŒ'}")
            print(f"   GPU ê°œìˆ˜: {hardware_info['cuda_device_count']}")
            print(f"   ì´ ë©”ëª¨ë¦¬: {hardware_info['total_memory']}GB")
            print(f"   ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {hardware_info['available_memory']}GB")
            print(f"   CPU ì½”ì–´: {hardware_info['cpu_cores']}")

            if hardware_info['cuda_available']:
                total_gpu_memory = 0
                for i in range(hardware_info['cuda_device_count']):
                    gpu_memory = hardware_info.get(f'gpu_{i}_memory', 0)
                    gpu_name = hardware_info.get(f'gpu_{i}_name', 'Unknown')
                    compute_cap = hardware_info.get(f'gpu_{i}_compute_capability', 'Unknown')
                    print(f"   GPU {i}: {gpu_name} ({gpu_memory}GB, CC {compute_cap})")
                    total_gpu_memory += gpu_memory

                print(f"\nğŸ¯ ì•ˆì „í•œ ëª¨ë¸ ì¶”ì²œ:")
                if total_gpu_memory >= 80:
                    print("   âœ… 70B ëª¨ë¸ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” ê¶Œì¥)")
                elif total_gpu_memory >= 32:
                    print("   âœ… 30B ëª¨ë¸ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” ê¶Œì¥)")
                elif total_gpu_memory >= 16:
                    print("   âœ… 13B ëª¨ë¸ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” ê¶Œì¥)")
                elif total_gpu_memory >= 8:
                    print("   âœ… 7B ëª¨ë¸ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” í•„ìˆ˜)")
                else:
                    print("   âš ï¸ CPU ì¶”ë¡  ê¶Œì¥ (ì‘ì€ ëª¨ë¸ë§Œ)")

            # ëª¨ë¸ í¬ê¸°ë³„ ì¶”ì²œ
            if args.model_size:
                print(f"\nğŸ¯ {args.model_size.upper()} ëª¨ë¸ ì•ˆì „ ì„¤ì •:")
                try:
                    recommended = HardwareDetector.get_recommended_config(args.model_size, hardware_info)
                    print(f"   ì¥ì¹˜: {recommended.device}")
                    print(f"   ë°ì´í„° íƒ€ì…: {recommended.dtype}")
                    print(f"   4-bit ì–‘ìí™”: {'âœ…' if recommended.load_in_4bit else 'âŒ'}")
                    print(f"   8-bit ì–‘ìí™”: {'âœ…' if recommended.load_in_8bit else 'âŒ'}")
                    if hasattr(recommended, 'cpu_offload'):
                        print(f"   CPU ì˜¤í”„ë¡œë“œ: {'âœ…' if recommended.cpu_offload else 'âŒ'}")
                except Exception as e:
                    print(f"   âŒ ì¶”ì²œ ì„¤ì • ìƒì„± ì‹¤íŒ¨: {e}")

        except Exception as e:
            if self.logger:
                self.logger.error(f"í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
            print(f"âŒ í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")

    async def run_optimize_command(self, args):
        """optimize ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"ğŸ”§ ì•ˆì „í•œ íŒŒë¼ë¯¸í„° ìµœì í™”: {args.model} on {args.dataset}")
        self._initialize()

        # ì•ˆì „ ëª¨ë“œ ì œí•œ
        if args.safe:
            max_samples = min(args.samples, 10)
            max_trials = min(args.trials, 5)
            print(f"   ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: ìƒ˜í”Œ {max_samples}ê°œ, ì‹œë„ {max_trials}íšŒ")
        else:
            max_samples = min(args.samples, 50)
            max_trials = min(args.trials, 20)

        try:
            # ìµœì í™”ê¸° ì´ˆê¸°í™”
            self.optimizer = SafeOptimizer()

            # ëª¨ë¸ ì„¤ì • í™•ì¸
            model_config = self.optimizer.config_manager.get_model_config(args.model)
            if not model_config:
                print(f"âŒ ëª¨ë¸ {args.model} ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
                for name in self.optimizer.config_manager.model_configs.keys():
                    print(f"     - {name}")
                return

            print(f"   ğŸ“‹ ëª¨ë¸: {model_config.model_path}")
            print(f"   ğŸ¯ ì „ëµ: {args.strategy}")
            print(f"   ğŸ“Š í‰ê°€ì: {args.evaluator}")

            # ìµœì í™” ì‹¤í–‰
            result = await self.optimizer.optimize_parameters(
                model_name=args.model,
                dataset_name=args.dataset,
                evaluator_type=args.evaluator,
                optimization_strategy=args.strategy,
                max_trials=max_trials,
                num_samples=max_samples,
                timeout_seconds=args.timeout
            )

            print(f"âœ… ìµœì í™” ì™„ë£Œ!")
            print(f"   ìµœê³  ì ìˆ˜: {result.best_score:.3f}")
            print(f"   ì†Œìš” ì‹œê°„: {result.total_time:.1f}ì´ˆ")

            print(f"\nğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:")
            params = result.best_params
            print(f"   Temperature: {params.temperature:.3f}")
            print(f"   Top-p: {params.top_p:.3f}")
            print(f"   Top-k: {params.top_k}")
            print(f"   Max tokens: {params.max_new_tokens}")
            print(f"   Repetition penalty: {params.repetition_penalty:.3f}")

            if result.recommendations:
                print(f"\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
                for i, rec in enumerate(result.recommendations, 1):
                    print(f"   {i}. {rec}")

            print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: optimization_results/{result.test_id}.json")

        except Exception as e:
            if self.logger:
                self.logger.error(f"ìµœì í™” ì‹¤íŒ¨: {e}")
            print(f"âŒ ìµœì í™” ì‹¤íŒ¨: {e}")

            # êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ
            if "CUDA out of memory" in str(e):
                print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                print("   1. --samples ìˆ˜ë¥¼ ì¤„ì´ì„¸ìš” (ì˜ˆ: --samples 5)")
                print("   2. --safe ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”")
                print("   3. ë” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”")
            elif "not found" in str(e):
                print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                print("   1. python safe_main.py list --type models (ëª¨ë¸ ëª©ë¡ í™•ì¸)")
                print("   2. python safe_main.py init --auto-detect (ì„¤ì • ì´ˆê¸°í™”)")

            if args.debug:
                traceback.print_exc()

    async def run_benchmark_command(self, args):
        """benchmark ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"âš¡ ì•ˆì „í•œ ë²¤ì¹˜ë§ˆí¬: {args.model} on {args.dataset}")
        self._initialize()

        # ì•ˆì „í•œ ì œí•œ
        max_samples = min(args.samples, 50)
        max_iterations = min(args.iterations, 3)

        try:
            self.optimizer = SafeOptimizer()

            # íŒŒë¼ë¯¸í„° ìƒì„±
            from config import InferenceParams
            params = InferenceParams(
                temperature=args.temperature,
                top_p=getattr(args, 'top_p', 0.9),  # args.top_p ëŒ€ì‹  ì•ˆì „í•œ ì ‘ê·¼
                max_new_tokens=min(args.max_tokens, 512)
            )

            print(f"   ğŸ“Š ìƒ˜í”Œ: {max_samples}ê°œ")
            print(f"   ğŸ”„ ë°˜ë³µ: {max_iterations}íšŒ")

            # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
            result = await self.optimizer.benchmark_model(
                model_name=args.model,
                dataset_name=args.dataset,
                params=params,
                num_samples=max_samples,
                iterations=max_iterations
            )

            print(f"âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥
            perf = result.performance_metrics
            print(f"\nğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
            print(f"   í† í°/ì´ˆ: {perf.get('tokens_per_second', 0):.1f}")
            print(f"   í‰ê·  ì§€ì—°ì‹œê°„: {perf.get('latency_avg', 0):.3f}ì´ˆ")
            print(f"   P95 ì§€ì—°ì‹œê°„: {perf.get('latency_p95', 0):.3f}ì´ˆ")
            print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {perf.get('memory_usage_mb', 0):.0f}MB")
            print(f"   ì²˜ë¦¬ëŸ‰: {perf.get('throughput', 0):.1f} req/sec")

            # ì •í™•ë„
            accuracy = perf.get('accuracy', 0)
            print(f"   ì •í™•ë„: {accuracy:.3f}")

            # ë¹„ìš© ë¶„ì„
            if result.cost_analysis:
                cost = result.cost_analysis
                print(f"\nğŸ’° ë¹„ìš© ë¶„ì„:")
                print(f"   ì‹œê°„ë‹¹ ë¹„ìš©: ${cost.get('cost_per_hour_usd', 0):.4f}")
                print(f"   1Kí† í°ë‹¹ ë¹„ìš©: ${cost.get('cost_per_1k_tokens_usd', 0):.6f}")

            print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: optimization_results/bench_{result.test_id}.json")

        except Exception as e:
            if self.logger:
                self.logger.error(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
            if args.debug:
                traceback.print_exc()

    async def run_compare_command(self, args):
        """compare ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"âš–ï¸ ì•ˆì „í•œ ëª¨ë¸ ë¹„êµ: {', '.join(args.models)} on {args.dataset}")
        self._initialize()

        max_samples = min(args.samples, 30)

        try:
            self.optimizer = SafeOptimizer()

            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
            from config import InferenceParams
            params = InferenceParams(temperature=0.1, top_p=0.9, max_new_tokens=200)

            results = {}
            for model in args.models:
                print(f"\nğŸ”„ {model} í…ŒìŠ¤íŠ¸ ì¤‘...")

                try:
                    result = await self.optimizer.benchmark_model(
                        model_name=model,
                        dataset_name=args.dataset,
                        params=params,
                        num_samples=max_samples,
                        iterations=1
                    )

                    results[model] = result
                    perf = result.performance_metrics
                    accuracy = perf.get('accuracy', 0)
                    speed = perf.get('tokens_per_second', 0)
                    print(f"   âœ… ì™„ë£Œ: ì •í™•ë„ {accuracy:.3f}, {speed:.1f} tokens/sec")

                except Exception as e:
                    print(f"   âŒ ì‹¤íŒ¨: {e}")
                    continue

            # ê²°ê³¼ ì •ë ¬ ë° ì¶œë ¥
            if results:
                print(f"\nğŸ“Š ë¹„êµ ê²°ê³¼ ({args.metric} ê¸°ì¤€):")
                print(f"{'ìˆœìœ„':<4} {'ëª¨ë¸':<20} {'ì •í™•ë„':<8} {'í† í°/ì´ˆ':<10} {'ë©”ëª¨ë¦¬(MB)':<12}")
                print("-" * 60)

                # ì •ë ¬
                if args.metric == 'accuracy':
                    sorted_results = sorted(results.items(),
                                            key=lambda x: x[1].performance_metrics.get('accuracy', 0),
                                            reverse=True)
                elif args.metric == 'speed':
                    sorted_results = sorted(results.items(),
                                            key=lambda x: x[1].performance_metrics.get('tokens_per_second', 0),
                                            reverse=True)
                else:  # efficiency
                    sorted_results = sorted(results.items(),
                                            key=lambda x: x[1].hardware_efficiency.get('overall_efficiency', 0),
                                            reverse=True)

                for i, (model, result) in enumerate(sorted_results, 1):
                    perf = result.performance_metrics
                    accuracy = perf.get('accuracy', 0)
                    speed = perf.get('tokens_per_second', 0)
                    memory = perf.get('memory_usage_mb', 0)

                    rank_symbol = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}."
                    print(f"{rank_symbol:<4} {model:<20} {accuracy:<8.3f} {speed:<10.1f} {memory:<12.0f}")
            else:
                print("âŒ ë¹„êµí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            if self.logger:
                self.logger.error(f"ëª¨ë¸ ë¹„êµ ì‹¤íŒ¨: {e}")
            print(f"âŒ ëª¨ë¸ ë¹„êµ ì‹¤íŒ¨: {e}")
            if args.debug:
                traceback.print_exc()

    def run_list_command(self, args):
        """list ëª…ë ¹ì–´ ì‹¤í–‰"""
        try:
            self._initialize()

            if not self.config_manager:
                self.config_manager = ConfigManager()

            if args.type == 'models':
                models = self.config_manager.model_configs
                print(f"ğŸ“‹ ë“±ë¡ëœ ëª¨ë¸ ({len(models)}ê°œ):")

                for name, config in models.items():
                    from config import SafetyChecker
                    warnings = SafetyChecker.check_model_config(config)
                    safety_status = "âš ï¸" if warnings else "âœ…"

                    print(f"   {safety_status} {name}")
                    print(f"      ê²½ë¡œ: {config.model_path}")
                    print(f"      ìœ í˜•: {config.model_type}")
                    print(f"      ì¥ì¹˜: {config.device}")
                    print(f"      ì–‘ìí™”: 4bit={config.load_in_4bit}, 8bit={config.load_in_8bit}")
                    if warnings:
                        print(f"      ê²½ê³ : {len(warnings)}ê°œ")
                    print()

            elif args.type == 'datasets':
                datasets = self.config_manager.test_configs
                print(f"ğŸ“‹ ë“±ë¡ëœ ë°ì´í„°ì…‹ ({len(datasets)}ê°œ):")

                for name, config in datasets.items():
                    data_file = Path(config.dataset_path)
                    exists = "âœ…" if data_file.exists() else "âŒ"
                    print(f"   {exists} {name}")
                    print(f"      ê²½ë¡œ: {config.dataset_path}")
                    print(f"      ìƒ˜í”Œ: {config.num_samples}ê°œ")
                    print()

            elif args.type == 'results':
                results_dir = Path("optimization_results")
                if results_dir.exists():
                    result_files = list(results_dir.glob("*.json"))
                    print(f"ğŸ“‹ ì €ì¥ëœ ê²°ê³¼ ({len(result_files)}ê°œ):")

                    for result_file in sorted(result_files, key=lambda x: x.stat().st_mtime, reverse=True)[:10]:
                        try:
                            with open(result_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)

                            test_type = "ğŸ”§" if 'best_score' in data else "âš¡"
                            model = data.get('model_name', 'Unknown')
                            dataset = data.get('dataset_name', 'Unknown')
                            timestamp = data.get('timestamp', '')[:16].replace('T', ' ')

                            print(f"   {test_type} {result_file.name}")
                            print(f"      {model} on {dataset} ({timestamp})")

                        except Exception:
                            print(f"   âŒ {result_file.name} (ì½ê¸° ì‹¤íŒ¨)")
                else:
                    print("ğŸ“‹ ì €ì¥ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            if self.logger:
                self.logger.error(f"ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            print(f"âŒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    def run_status_command(self, args):
        """status ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€")
        self.show_system_status()

        # ì¶”ê°€ ìƒíƒœ ì •ë³´
        if IMPORTS_OK:
            try:
                from config import get_resource_manager
                resource_manager = get_resource_manager()
                memory_usage = resource_manager.get_memory_usage()

                if memory_usage:
                    print(f"\nğŸ¯ í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:")
                    for key, value in memory_usage.items():
                        if isinstance(value, float) and 'percent' in key:
                            status = "âš ï¸" if value > 80 else "âœ…"
                            print(f"   {status} {key}: {value:.1f}%")
                        elif isinstance(value, float) and 'gb' in key:
                            print(f"      {key}: {value:.2f}GB")

            except Exception as e:
                print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")

    def run_clean_command(self, args):
        """clean ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")

        cleaned_items = []

        try:
            if args.cache or args.all:
                # CUDA ìºì‹œ ì •ë¦¬
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        cleaned_items.append("CUDA ìºì‹œ")
                except:
                    pass

                # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                gc.collect()
                cleaned_items.append("Python ê°€ë¹„ì§€")

            if args.logs or args.all:
                # ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬ (7ì¼ ì´ìƒ)
                log_dir = Path("logs")
                if log_dir.exists():
                    current_time = time.time()
                    old_logs = []

                    for log_file in log_dir.glob("*.log"):
                        if current_time - log_file.stat().st_mtime > 7 * 24 * 3600:  # 7ì¼
                            old_logs.append(log_file)

                    for log_file in old_logs:
                        log_file.unlink()

                    if old_logs:
                        cleaned_items.append(f"{len(old_logs)}ê°œ ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼")

            if args.results or args.all:
                # ì‚¬ìš©ì í™•ì¸ í›„ ê²°ê³¼ ì •ë¦¬
                results_dir = Path("optimization_results")
                if results_dir.exists():
                    result_files = list(results_dir.glob("*.json"))
                    if result_files:
                        response = input(f"âš ï¸ {len(result_files)}ê°œ ê²°ê³¼ íŒŒì¼ì„ ì •ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                        if response.lower() == 'y':
                            for result_file in result_files:
                                result_file.unlink()
                            cleaned_items.append(f"{len(result_files)}ê°œ ê²°ê³¼ íŒŒì¼")

            # HuggingFace ìºì‹œ ì •ë¦¬ (ì„ íƒì )
            if args.all:
                hf_cache = Path.home() / ".cache" / "huggingface"
                if hf_cache.exists():
                    response = input("âš ï¸ HuggingFace ìºì‹œë¥¼ ì •ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                    if response.lower() == 'y':
                        shutil.rmtree(hf_cache, ignore_errors=True)
                        cleaned_items.append("HuggingFace ìºì‹œ")

            if cleaned_items:
                print("âœ… ì •ë¦¬ ì™„ë£Œ:")
                for item in cleaned_items:
                    print(f"   - {item}")
            else:
                print("âœ… ì •ë¦¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            if self.logger:
                self.logger.error(f"ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")
            print(f"âŒ ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")

    def show_welcome_screen(self):
        """í™˜ì˜ í™”ë©´"""
        self.print_banner()
        print("ğŸ›¡ï¸ ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")

        print("\nğŸš€ ë¹ ë¥¸ ì‹œì‘ (ì•ˆì „ ëª¨ë“œ):")
        print("1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”: python safe_main.py init --auto-detect")
        print("2. í•˜ë“œì›¨ì–´ í™•ì¸: python safe_main.py hardware")
        print("3. ì‹œìŠ¤í…œ ìƒíƒœ: python safe_main.py status")
        print("4. ì•ˆì „í•œ ìµœì í™”: python safe_main.py optimize --model qwen2.5-7b --dataset korean_math --samples 10 --safe")
        print("5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬: python safe_main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 20")

        print("\nğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        print("   âœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ - ìë™ ë¦¬ì†ŒìŠ¤ ì •ë¦¬")
        print("   âœ… ìŠ¤ë ˆë“œ ì•ˆì „ì„± - ë™ì‹œì„± ë¬¸ì œ í•´ê²°")
        print("   âœ… ì˜ì¡´ì„± ì•ˆì •ì„± - Optuna ê¸°ë°˜ ìµœì í™”")
        print("   âœ… ì˜¤ë¥˜ ë³µêµ¬ - ê°•í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬")
        print("   âœ… ë³´ì•ˆ ê°•í™” - ì…ë ¥ ê²€ì¦ ë° ì•ˆì „ ëª¨ë“œ")

        print("\nâš¡ ì•ˆì „ ì‚¬ìš© íŒ:")
        print("   ğŸ›¡ï¸ ì²˜ìŒ ì‚¬ìš©: --safe ì˜µì…˜ í•„ìˆ˜")
        print("   ğŸ’¾ ë©”ëª¨ë¦¬ ì ˆì•½: --samples 10-20 ê¶Œì¥")
        print("   ğŸ› ë¬¸ì œ í•´ê²°: --debug ì˜µì…˜ í™œìš©")
        print("   ğŸ”§ ì‹œìŠ¤í…œ ì •ë¦¬: clean ëª…ë ¹ì–´ ì •ê¸° ì‹¤í–‰")

        print("\nğŸ’¡ ë„ì›€ë§:")
        print("   ì „ì²´ ëª…ë ¹ì–´: python safe_main.py --help")
        print("   ëª…ë ¹ì–´ë³„ ë„ì›€ë§: python safe_main.py [ëª…ë ¹ì–´] --help")

        # ì‹œìŠ¤í…œ ìƒíƒœ ê°„ë‹¨íˆ í‘œì‹œ
        self.show_system_status()

    async def main(self):
        """ë©”ì¸ í•¨ìˆ˜"""
        parser = self.create_argument_parser()

        # ì¸ìê°€ ì—†ìœ¼ë©´ í™˜ì˜ í™”ë©´
        if len(sys.argv) == 1:
            self.show_welcome_screen()
            return

        try:
            args = parser.parse_args()
        except SystemExit:
            return

        # ë¡œê¹… ì„¤ì •
        setup_safe_logging(args.debug)

        if not args.command:
            self.print_banner()
            parser.print_help()
            return

        self.print_banner()

        # ë…ë¦½ì  ëª…ë ¹ì–´ë“¤ (ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ë¶ˆí•„ìš”)
        if args.command in ['init', 'hardware', 'list', 'status', 'clean']:
            try:
                if args.command == 'init':
                    self.run_init_command(args)
                elif args.command == 'hardware':
                    self.run_hardware_command(args)
                elif args.command == 'list':
                    self.run_list_command(args)
                elif args.command == 'status':
                    self.run_status_command(args)
                elif args.command == 'clean':
                    self.run_clean_command(args)
                return
            except KeyboardInterrupt:
                print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
            except Exception as e:
                if self.logger:
                    self.logger.error(f"ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                print(f"âŒ ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                if args.debug:
                    traceback.print_exc()
                return

        # ë³µì¡í•œ ëª…ë ¹ì–´ë“¤ (ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ í•„ìš”)
        if not self.check_system_requirements():
            print("\nâš ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            if not args.safe:
                response = input("ì•ˆì „ ëª¨ë“œë¡œ ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                if response.lower() != 'y':
                    return
                args.safe = True

        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            tasks = []

            # ëª…ë ¹ ì‹¤í–‰
            if args.command == 'optimize':
                command_task = asyncio.create_task(self.run_optimize_command(args))
            elif args.command == 'benchmark':
                command_task = asyncio.create_task(self.run_benchmark_command(args))
            elif args.command == 'compare':
                command_task = asyncio.create_task(self.run_compare_command(args))
            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {args.command}")
                return

            tasks.append(command_task)

            # íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ (í•„ìš”í•œ ê²½ìš°)
            if args.timeout > 0:
                timeout_task = asyncio.create_task(asyncio.sleep(args.timeout))
                tasks.append(timeout_task)

            # íƒœìŠ¤í¬ ì‹¤í–‰
            if len(tasks) > 1:
                done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)

                # íƒ€ì„ì•„ì›ƒ ì²´í¬
                if timeout_task in done:
                    command_task.cancel()
                    print(f"\nâ° ì‹œê°„ ì´ˆê³¼ ({args.timeout}ì´ˆ)")
                else:
                    timeout_task.cancel()
            else:
                await command_task

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            if self.logger:
                self.logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            if args.debug:
                traceback.print_exc()
        finally:
            # ì •ë¦¬ ì‘ì—…
            print("\nğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
            try:
                if self.optimizer:
                    # ìµœì í™”ê¸° ì •ë¦¬ëŠ” ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
                    pass
                cleanup_all()
            except Exception as e:
                if self.logger:
                    self.logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            print("âœ… ì •ë¦¬ ì™„ë£Œ")


def main():
    """ì§„ì…ì """
    # ê¸°ë³¸ ì˜¤ë¥˜ ì²˜ë¦¬
    if not IMPORTS_OK:
        print("âŒ í•„ìˆ˜ ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì˜¤ë¥˜: {IMPORT_ERROR}")
        print("\nğŸ“¦ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   pip install torch transformers numpy pandas optuna psutil")
        sys.exit(1)

    try:
        cli = SafeCLI()
        asyncio.run(cli.main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        print("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”: --safe")
        print("ğŸ› ë¬¸ì œ ì§€ì† ì‹œ --debug ì˜µì…˜ìœ¼ë¡œ ìƒì„¸ ì •ë³´ í™•ì¸")
    finally:
        # ìµœì¢… ì •ë¦¬
        cleanup_all()


if __name__ == "__main__":
    main()


    def create_argument_parser(self) -> argparse.ArgumentParser:
        """CLI ì¸ì íŒŒì„œ ìƒì„±"""
        parser = argparse.ArgumentParser(
            description='ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ',
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ì•ˆì „í•œ ì‚¬ìš© ì˜ˆì‹œ:
  python safe_main.py init --auto-detect              # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
  python safe_main.py hardware                        # í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸
  python safe_main.py optimize --model qwen2.5-7b --dataset korean_math --samples 20 --safe
  python safe_main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 30
  python safe_main.py compare --models qwen2.5-7b llama2-7b --dataset korean_math
  python safe_main.py status                          # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

ì•ˆì „ ëª¨ë“œ ì˜µì…˜:
  --safe: ë©”ëª¨ë¦¬ì™€ ì„±ëŠ¥ì„ ì œí•œí•˜ì—¬ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
  --debug: ìƒì„¸í•œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
  --timeout: ì‘ì—… ì‹œê°„ ì œí•œ (ì´ˆ)
            """
        )

        # ì „ì—­ ì˜µì…˜
        parser.add_argument('--safe', action='store_true', help='ì•ˆì „ ëª¨ë“œë¡œ ì‹¤í–‰')
        parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ')
        parser.add_argument('--timeout', type=int, default=3600, help='ì‘ì—… ì‹œê°„ ì œí•œ (ì´ˆ)')

        subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')

        # init ëª…ë ¹ì–´
        init_parser = subparsers.add_parser('init', help='ì‹œìŠ¤í…œ ì´ˆê¸°í™”')
        init_parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ ì„¤ì • ë®ì–´ì“°ê¸°')
        init_parser.add_argument('--auto-detect', action='store_true', help='í•˜ë“œì›¨ì–´ ìë™ ê°ì§€')

        # hardware ëª…ë ¹ì–´
        hardware_parser = subparsers.add_parser('hardware', help='í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸')
        hardware_parser.add_argument('--model-size', choices=['1b', '3b', '7b', '13b', '30b', '70b'],
                                     help='ëª¨ë¸ í¬ê¸°ë³„ ì¶”ì²œ')

        # optimize ëª…ë ¹ì–´
        optimize_parser = subparsers.add_parser('optimize', help='íŒŒë¼ë¯¸í„° ìµœì í™”')
        optimize_parser.add_argument('--model', required=True, help='ëª¨ë¸ ì´ë¦„')
        optimize_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        optimize_parser.add_argument('--strategy', choices=['optuna', 'grid_search'],
                                     default='grid_search', help='ìµœì í™” ì „ëµ')
        optimize_parser.add_argument('--trials', type=int, default=10, help='ìµœì í™” ì‹œë„ íšŸìˆ˜')
        optimize_parser.add_argument('--samples', type=int, default=20, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        optimize_parser.add_argument('--evaluator', choices=['exact_match', 'contains', 'similarity'],
                                     default='similarity', help='í‰ê°€ì ìœ í˜•')

        # benchmark ëª…ë ¹ì–´
        benchmark_parser = subparsers.add_parser('benchmark', help='ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬')
        benchmark_parser.add_argument('--model', required=True, help='ëª¨ë¸ ì´ë¦„')
        benchmark_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        benchmark_parser.add_argument('--samples', type=int, default=30, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        benchmark_parser.add_argument('--iterations', type=int, default=1, help='ë°˜ë³µ íšŸìˆ˜')
        benchmark_parser.add_argument('--temperature', type=float, default=0.1, help='Temperature')
        benchmark_parser.add_argument('--top-p', type=float, default=0.9, help='Top-p')
        benchmark_parser.add_argument('--max-tokens', type=int, default=200, help='ìµœëŒ€ í† í° ìˆ˜')

        # compare ëª…ë ¹ì–´
        compare_parser = subparsers.add_parser('compare', help='ëª¨ë¸ ë¹„êµ')
        compare_parser.add_argument('--models', nargs='+', required=True, help='ë¹„êµí•  ëª¨ë¸ë“¤')
        compare_parser.add_argument('--dataset', required=True, help='ë°ì´í„°ì…‹ ì´ë¦„')
        compare_parser.add_argument('--samples', type=int, default=20, help='í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜')
        compare_parser.add_argument('--metric', choices=['accuracy', 'speed', 'efficiency'],
                                    default='accuracy', help='ë¹„êµ ê¸°ì¤€')

        # list ëª…ë ¹ì–´
        list_parser = subparsers.add_parser('list', help='ì •ë³´ ì¡°íšŒ')
        list_parser.add_argument('--type', choices=['models', 'datasets', 'results'],
                                 default='models', help='ì¡°íšŒí•  ì •ë³´ ìœ í˜•')

        # status ëª…ë ¹ì–´
        status_parser = subparsers.add_parser('status', help='ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸')

        # clean ëª…ë ¹ì–´
        clean_parser = subparsers.add_parser('clean', help='ì‹œìŠ¤í…œ ì •ë¦¬')
        clean_parser.add_argument('--cache', action='store_true', help='ìºì‹œ ì •ë¦¬')
        clean_parser.add_argument('--logs', action='store_true', help='ë¡œê·¸ ì •ë¦¬')
        clean_parser.add_argument('--results', action='store_true', help='ê²°ê³¼ ì •ë¦¬')
        clean_parser.add_argument('--all', action='store_true', help='ëª¨ë“  ì •ë¦¬')

        return parser


    def print_banner(self):
        """ì‹œìŠ¤í…œ ë°°ë„ˆ ì¶œë ¥"""
        banner = """
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚          ğŸ›¡ï¸ ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ         â”‚
â”‚              Safe Open Source LLM Optimizer               â”‚
â”‚                    âœ… Security Enhanced                    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""
        print(banner)


    def check_system_requirements(self) -> bool:
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        requirements_met = True
        issues = []

        # Python ë²„ì „ í™•ì¸
        if sys.version_info < (3, 8):
            issues.append(f"Python 3.8+ í•„ìš” (í˜„ì¬: {sys.version})")
            requirements_met = False

        # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
        required_packages = {
            'torch': 'PyTorch',
            'transformers': 'HuggingFace Transformers',
            'numpy': 'NumPy',
            'psutil': 'psutil'
        }

        missing_packages = []
        for package, description in required_packages.items():
            try:
                __import__(package)
            except ImportError:
                missing_packages.append(f"{package} ({description})")

        if missing_packages:
            issues.append(f"ëˆ„ë½ëœ í•„ìˆ˜ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
            requirements_met = False

        # ì„ íƒì  íŒ¨í‚¤ì§€ í™•ì¸
        optional_packages = {
            'optuna': 'Optuna (ê³ ê¸‰ ìµœì í™”ìš©)',
            'plotly': 'Plotly (ì‹œê°í™”ìš©)'
        }

        missing_optional = []
        for package, description in optional_packages.items():
            try:
                __import__(package)
            except ImportError:
                missing_optional.append(f"{package} ({description})")

        if missing_optional:
            print(f"âš ï¸ ì„ íƒì  íŒ¨í‚¤ì§€ ëˆ„ë½: {', '.join(missing_optional)}")
            print("  ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # í•˜ë“œì›¨ì–´ ì •ë³´
        try:
            hardware_info = HardwareDetector.detect_hardware()
            if hardware_info['cuda_available']:
                gpu_count = hardware_info['cuda_device_count']
                total_memory = sum(
                    hardware_info.get(f'gpu_{i}_memory', 0)
                    for i in range(gpu_count)
                )
                print(f"âœ… GPU ê°ì§€: {gpu_count}ê°œ, ì´ ë©”ëª¨ë¦¬: {total_memory}GB")
            else:
                print("âš ï¸ CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ë¶ˆê°€: {e}")

        # ì˜¤ë¥˜ ì¶œë ¥
        if issues:
            print(f"âŒ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±:")
            for issue in issues:
                print(f"   - {issue}")

            print(f"\nğŸ’¡ í•´ê²° ë°©ë²•:")
            if missing_packages:
                packages = [p.split(' ')[0] for p in missing_packages]
                print(f"   pip install {' '.join(packages)}")

        return requirements_met


    def show_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
        print("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")

        # ì„¤ì • íŒŒì¼ í™•ì¸
        config_file = Path("llm_config.json")
        if config_file.exists():
            try:
                self.config_manager = ConfigManager()
                model_count = len(self.config_manager.model_configs)
                print(f"   âœ… ì„¤ì • íŒŒì¼: {model_count}ê°œ ëª¨ë¸ ë“±ë¡ë¨")

                # ì„¤ì • ê²€ì¦
                validation_results = self.config_manager.validate_all_configs()
                if validation_results:
                    print(f"   âš ï¸ ì„¤ì • ë¬¸ì œ: {len(validation_results)}ê°œ ëª¨ë¸ì—ì„œ ê²½ê³ ")
                else:
                    print("   âœ… ëª¨ë“  ì„¤ì •ì´ ì•ˆì „í•©ë‹ˆë‹¤")

            except Exception as e:
                print(f"   âŒ ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        else:
            print("   âŒ ì„¤ì • íŒŒì¼ ì—†ìŒ (init ëª…ë ¹ ì‹¤í–‰ í•„ìš”)")

        # ë””ë ‰í† ë¦¬ í™•ì¸
        directories = {
            "data": "ë°ì´í„°ì…‹",
            "optimization_results": "ìµœì í™” ê²°ê³¼",
            "logs": "ë¡œê·¸ íŒŒì¼"
        }

        for dir_name, description in directories.items():
            dir_path = Path(dir_name)
            if dir_path.exists():
                file_count = len(list(dir_path.glob("*")))
                print(f"   âœ… {description}: {file_count}ê°œ íŒŒì¼")
            else:
                print(f"   âŒ {description} ë””ë ‰í† ë¦¬ ì—†ìŒ")

        # í•˜ë“œì›¨ì–´ ì •ë³´
        try:
            hardware_info = HardwareDetector.detect_hardware()
            print(f"   ğŸ’» ì‹œìŠ¤í…œ:")
            print(f"      CPU: {hardware_info['cpu_cores']}ì½”ì–´")
            print(f"      ë©”ëª¨ë¦¬: {hardware_info['available_memory']}/{hardware_info['total_memory']}GB")

            if hardware_info['cuda_available']:
                for i in range(hardware_info['cuda_device_count']):
                    gpu_name = hardware_info.get(f'gpu_{i}_name', f'GPU {i}')
                    gpu_memory = hardware_info.get(f'gpu_{i}_memory', 0)
                    print(f"      {gpu_name}: {gpu_memory}GB")
            else:
                print(f"      GPU: ì‚¬ìš© ë¶ˆê°€")

        except Exception as e:
            print(f"   âš ï¸ í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ë¶ˆê°€: {e}")


    def run_init_command(self, args):
        """init ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ”§ ì•ˆì „í•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")

        config_file = Path("llm_config.json")

        if config_file.exists() and not args.force:
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {config_file}")
            print("   ë®ì–´ì“°ë ¤ë©´ --force ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return

        try:
            # ì„¤ì • ë§¤ë‹ˆì € ìƒì„±
            self.config_manager = ConfigManager()
            print(f"âœ… ì•ˆì „í•œ ì„¤ì • íŒŒì¼ ìƒì„±: {config_file}")

            # ë””ë ‰í† ë¦¬ ìƒì„±
            directories = ["data", "optimization_results", "logs"]
            for directory in directories:
                Path(directory).mkdir(exist_ok=True)
                print(f"   âœ… {directory} ë””ë ‰í† ë¦¬ ìƒì„±")

            # í•˜ë“œì›¨ì–´ ìë™ ê°ì§€
            if args.auto_detect:
                print("ğŸ” í•˜ë“œì›¨ì–´ ìë™ ê°ì§€...")
                hardware_info = HardwareDetector.detect_hardware()
                print(f"   GPU: {hardware_info['cuda_device_count']}ê°œ")
                print(f"   ë©”ëª¨ë¦¬: {hardware_info['total_memory']}GB")

                if hardware_info['cuda_available']:
                    total_gpu_memory = sum(
                        hardware_info.get(f'gpu_{i}_memory', 0)
                        for i in range(hardware_info['cuda_device_count'])
                    )
                    print(f"   GPU ë©”ëª¨ë¦¬: {total_gpu_memory}GB")

            print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
            print("1. í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸: python safe_main.py hardware")
            print("2. ëª¨ë¸ ëª©ë¡ í™•ì¸: python safe_main.py list --type models")
            print(
                "3. ì•ˆì „í•œ ìµœì í™” ì‹¤í–‰: python safe_main.py optimize --model qwen2.5-7b --dataset korean_math --samples 10 --safe")

        except Exception as e:
            self.logger.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            if args.debug:
                traceback.print_exc()


    def run_hardware_command(self, args):
        """hardware ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ’» í•˜ë“œì›¨ì–´ ì •ë³´ ë¶„ì„")

        try:
            hardware_info = HardwareDetector.detect_hardware()

            print(f"\nğŸ” ê°ì§€ëœ í•˜ë“œì›¨ì–´:")
            print(f"   í”Œë«í¼: {hardware_info['platform']}")
            print(f"   CUDA ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if hardware_info['cuda_available'] else 'âŒ'}")
            print(f"   MPS ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if hardware_info.get('mps_available', False) else 'âŒ'}")
            print(f"   GPU ê°œìˆ˜: {hardware_info['cuda_device_count']}")
            print(f"   ì´ ë©”ëª¨ë¦¬: {hardware_info['total_memory']}GB")
            print(f"   ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {hardware_info['available_memory']}GB")
            print(f"   CPU ì½”ì–´: {hardware_info['cpu_cores']}")

            if hardware_info['cuda_available']:
                total_gpu_memory = 0
                for i in range(hardware_info['cuda_device_count']):
                    gpu_memory = hardware_info.get(f'gpu_{i}_memory', 0)
                    gpu_name = hardware_info.get(f'gpu_{i}_name', 'Unknown')
                    compute_cap = hardware_info.get(f'gpu_{i}_compute_capability', 'Unknown')
                    print(f"   GPU {i}: {gpu_name} ({gpu_memory}GB, CC {compute_cap})")
                    total_gpu_memory += gpu_memory

                print(f"\nğŸ¯ ì•ˆì „í•œ ëª¨ë¸ ì¶”ì²œ:")
                if total_gpu_memory >= 80:
                    print("   âœ… 70B ëª¨ë¸ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” ê¶Œì¥)")
                elif total_gpu_memory >= 32:
                    print("   âœ… 30B ëª¨ë¸ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” ê¶Œì¥)")
                elif total_gpu_memory >= 16:
                    print("   âœ… 13B ëª¨ë¸ê¹Œì§€ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” ê¶Œì¥)")
                elif total_gpu_memory >= 8:
                    print("   âœ… 7B ëª¨ë¸ ì‹¤í–‰ ê°€ëŠ¥ (4-bit ì–‘ìí™” í•„ìˆ˜)")
                else:
                    print("   âš ï¸ CPU ì¶”ë¡  ê¶Œì¥ (ì‘ì€ ëª¨ë¸ë§Œ)")

            # ëª¨ë¸ í¬ê¸°ë³„ ì¶”ì²œ
            if args.model_size:
                print(f"\nğŸ¯ {args.model_size.upper()} ëª¨ë¸ ì•ˆì „ ì„¤ì •:")
                try:
                    recommended = HardwareDetector.get_recommended_config(args.model_size, hardware_info)
                    print(f"   ì¥ì¹˜: {recommended.device}")
                    print(f"   ë°ì´í„° íƒ€ì…: {recommended.dtype}")
                    print(f"   4-bit ì–‘ìí™”: {'âœ…' if recommended.load_in_4bit else 'âŒ'}")
                    print(f"   8-bit ì–‘ìí™”: {'âœ…' if recommended.load_in_8bit else 'âŒ'}")
                    print(f"   CPU ì˜¤í”„ë¡œë“œ: {'âœ…' if recommended.cpu_offload else 'âŒ'}")
                except Exception as e:
                    print(f"   âŒ ì¶”ì²œ ì„¤ì • ìƒì„± ì‹¤íŒ¨: {e}")

        except Exception as e:
            self.logger.error(f"í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
            print(f"âŒ í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")


    async def run_optimize_command(self, args):
        """optimize ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"ğŸ”§ ì•ˆì „í•œ íŒŒë¼ë¯¸í„° ìµœì í™”: {args.model} on {args.dataset}")

        # ì•ˆì „ ëª¨ë“œ ì œí•œ
        if args.safe:
            max_samples = min(args.samples, 10)
            max_trials = min(args.trials, 5)
            print(f"   ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œ: ìƒ˜í”Œ {max_samples}ê°œ, ì‹œë„ {max_trials}íšŒ")
        else:
            max_samples = min(args.samples, 50)
            max_trials = min(args.trials, 20)

        try:
            # ìµœì í™”ê¸° ì´ˆê¸°í™”
            self.optimizer = SafeOptimizer()

            # ëª¨ë¸ ì„¤ì • í™•ì¸
            model_config = self.optimizer.config_manager.get_model_config(args.model)
            if not model_config:
                print(f"âŒ ëª¨ë¸ {args.model} ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
                for name in self.optimizer.config_manager.model_configs.keys():
                    print(f"     - {name}")
                return

            print(f"   ğŸ“‹ ëª¨ë¸: {model_config.model_path}")
            print(f"   ğŸ¯ ì „ëµ: {args.strategy}")
            print(f"   ğŸ“Š í‰ê°€ì: {args.evaluator}")

            # ìµœì í™” ì‹¤í–‰
            result = await self.optimizer.optimize_parameters(
                model_name=args.model,
                dataset_name=args.dataset,
                evaluator_type=args.evaluator,
                optimization_strategy=args.strategy,
                max_trials=max_trials,
                num_samples=max_samples,
                timeout_seconds=args.timeout
            )

            print(f"âœ… ìµœì í™” ì™„ë£Œ!")
            print(f"   ìµœê³  ì ìˆ˜: {result.best_score:.3f}")
            print(f"   ì†Œìš” ì‹œê°„: {result.total_time:.1f}ì´ˆ")

            print(f"\nğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:")
            params = result.best_params
            print(f"   Temperature: {params.temperature:.3f}")
            print(f"   Top-p: {params.top_p:.3f}")
            print(f"   Top-k: {params.top_k}")
            print(f"   Max tokens: {params.max_new_tokens}")
            print(f"   Repetition penalty: {params.repetition_penalty:.3f}")

            if result.recommendations:
                print(f"\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
                for i, rec in enumerate(result.recommendations, 1):
                    print(f"   {i}. {rec}")

            print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: optimization_results/{result.test_id}.json")

        except Exception as e:
            self.logger.error(f"ìµœì í™” ì‹¤íŒ¨: {e}")
            print(f"âŒ ìµœì í™” ì‹¤íŒ¨: {e}")

            # êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ
            if "CUDA out of memory" in str(e):
                print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                print("   1. --samples ìˆ˜ë¥¼ ì¤„ì´ì„¸ìš” (ì˜ˆ: --samples 5)")
                print("   2. --safe ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”")
                print("   3. ë” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”")
            elif "not found" in str(e):
                print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                print("   1. python safe_main.py list --type models (ëª¨ë¸ ëª©ë¡ í™•ì¸)")
                print("   2. python safe_main.py init --auto-detect (ì„¤ì • ì´ˆê¸°í™”)")

            if args.debug:
                traceback.print_exc()


    async def run_benchmark_command(self, args):
        """benchmark ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"âš¡ ì•ˆì „í•œ ë²¤ì¹˜ë§ˆí¬: {args.model} on {args.dataset}")

        # ì•ˆì „í•œ ì œí•œ
        max_samples = min(args.samples, 50)
        max_iterations = min(args.iterations, 3)

        try:
            self.optimizer = SafeOptimizer()

            # íŒŒë¼ë¯¸í„° ìƒì„±
            from config import InferenceParams
            params = InferenceParams(
                temperature=args.temperature,
                top_p=args.top_p,
                max_new_tokens=min(args.max_tokens, 512)
            )

            print(f"   ğŸ“Š ìƒ˜í”Œ: {max_samples}ê°œ")
            print(f"   ğŸ”„ ë°˜ë³µ: {max_iterations}íšŒ")

            # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
            result = await self.optimizer.benchmark_model(
                model_name=args.model,
                dataset_name=args.dataset,
                params=params,
                num_samples=max_samples,
                iterations=max_iterations
            )

            print(f"âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥
            perf = result.performance_metrics
            print(f"\nğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
            print(f"   í† í°/ì´ˆ: {perf.get('tokens_per_second', 0):.1f}")
            print(f"   í‰ê·  ì§€ì—°ì‹œê°„: {perf.get('latency_avg', 0):.3f}ì´ˆ")
            print(f"   P95 ì§€ì—°ì‹œê°„: {perf.get('latency_p95', 0):.3f}ì´ˆ")
            print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {perf.get('memory_usage_mb', 0):.0f}MB")
            print(f"   ì²˜ë¦¬ëŸ‰: {perf.get('throughput', 0):.1f} req/sec")

            # ì •í™•ë„
            accuracy = perf.get('accuracy', 0)
            print(f"   ì •í™•ë„: {accuracy:.3f}")

            # ë¹„ìš© ë¶„ì„
            if result.cost_analysis:
                cost = result.cost_analysis
                print(f"\nğŸ’° ë¹„ìš© ë¶„ì„:")
                print(f"   ì‹œê°„ë‹¹ ë¹„ìš©: ${cost.get('cost_per_hour_usd', 0):.4f}")
                print(f"   1Kí† í°ë‹¹ ë¹„ìš©: ${cost.get('cost_per_1k_tokens_usd', 0):.6f}")

            print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: optimization_results/bench_{result.test_id}.json")

        except Exception as e:
            self.logger.error(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
            if args.debug:
                traceback.print_exc()


    async def run_compare_command(self, args):
        """compare ëª…ë ¹ì–´ ì‹¤í–‰"""
        print(f"âš–ï¸ ì•ˆì „í•œ ëª¨ë¸ ë¹„êµ: {', '.join(args.models)} on {args.dataset}")

        max_samples = min(args.samples, 30)

        try:
            self.optimizer = SafeOptimizer()

            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
            from config import InferenceParams
            params = InferenceParams(temperature=0.1, top_p=0.9, max_new_tokens=200)

            results = {}
            for model in args.models:
                print(f"\nğŸ”„ {model} í…ŒìŠ¤íŠ¸ ì¤‘...")

                try:
                    result = await self.optimizer.benchmark_model(
                        model_name=model,
                        dataset_name=args.dataset,
                        params=params,
                        num_samples=max_samples,
                        iterations=1
                    )

                    results[model] = result
                    perf = result.performance_metrics
                    accuracy = perf.get('accuracy', 0)
                    speed = perf.get('tokens_per_second', 0)
                    print(f"   âœ… ì™„ë£Œ: ì •í™•ë„ {accuracy:.3f}, {speed:.1f} tokens/sec")

                except Exception as e:
                    print(f"   âŒ ì‹¤íŒ¨: {e}")
                    continue

            # ê²°ê³¼ ì •ë ¬ ë° ì¶œë ¥
            if results:
                print(f"\nğŸ“Š ë¹„êµ ê²°ê³¼ ({args.metric} ê¸°ì¤€):")
                print(f"{'ìˆœìœ„':<4} {'ëª¨ë¸':<20} {'ì •í™•ë„':<8} {'í† í°/ì´ˆ':<10} {'ë©”ëª¨ë¦¬(MB)':<12}")
                print("-" * 60)

                # ì •ë ¬
                if args.metric == 'accuracy':
                    sorted_results = sorted(results.items(),
                                            key=lambda x: x[1].performance_metrics.get('accuracy', 0),
                                            reverse=True)
                elif args.metric == 'speed':
                    sorted_results = sorted(results.items(),
                                            key=lambda x: x[1].performance_metrics.get('tokens_per_second', 0),
                                            reverse=True)
                else:  # efficiency
                    sorted_results = sorted(results.items(),
                                            key=lambda x: x[1].hardware_efficiency.get('overall_efficiency', 0),
                                            reverse=True)

                for i, (model, result) in enumerate(sorted_results, 1):
                    perf = result.performance_metrics
                    accuracy = perf.get('accuracy', 0)
                    speed = perf.get('tokens_per_second', 0)
                    memory = perf.get('memory_usage_mb', 0)

                    rank_symbol = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}."
                    print(f"{rank_symbol:<4} {model:<20} {accuracy:<8.3f} {speed:<10.1f} {memory:<12.0f}")
            else:
                print("âŒ ë¹„êµí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ë¹„êµ ì‹¤íŒ¨: {e}")
            print(f"âŒ ëª¨ë¸ ë¹„êµ ì‹¤íŒ¨: {e}")
            if args.debug:
                traceback.print_exc()


    def run_list_command(self, args):
        """list ëª…ë ¹ì–´ ì‹¤í–‰"""
        try:
            if not self.config_manager:
                self.config_manager = ConfigManager()

            if args.type == 'models':
                models = self.config_manager.model_configs
                print(f"ğŸ“‹ ë“±ë¡ëœ ëª¨ë¸ ({len(models)}ê°œ):")

                for name, config in models.items():
                    from config import SafetyChecker
                    warnings = SafetyChecker.check_model_config(config)
                    safety_status = "âš ï¸" if warnings else "âœ…"

                    print(f"   {safety_status} {name}")
                    print(f"      ê²½ë¡œ: {config.model_path}")
                    print(f"      ìœ í˜•: {config.model_type}")
                    print(f"      ì¥ì¹˜: {config.device}")
                    print(f"      ì–‘ìí™”: 4bit={config.load_in_4bit}, 8bit={config.load_in_8bit}")
                    if warnings:
                        print(f"      ê²½ê³ : {len(warnings)}ê°œ")
                    print()

            elif args.type == 'datasets':
                datasets = self.config_manager.test_configs
                print(f"ğŸ“‹ ë“±ë¡ëœ ë°ì´í„°ì…‹ ({len(datasets)}ê°œ):")

                for name, config in datasets.items():
                    data_file = Path(config.dataset_path)
                    exists = "âœ…" if data_file.exists() else "âŒ"
                    print(f"   {exists} {name}")
                    print(f"      ê²½ë¡œ: {config.dataset_path}")
                    print(f"      ìƒ˜í”Œ: {config.num_samples}ê°œ")
                    print()

            elif args.type == 'results':
                results_dir = Path("optimization_results")
                if results_dir.exists():
                    result_files = list(results_dir.glob("*.json"))
                    print(f"ğŸ“‹ ì €ì¥ëœ ê²°ê³¼ ({len(result_files)}ê°œ):")

                    for result_file in sorted(result_files, key=lambda x: x.stat().st_mtime, reverse=True)[:10]:
                        try:
                            with open(result_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)

                            test_type = "ğŸ”§" if 'best_score' in data else "âš¡"
                            model = data.get('model_name', 'Unknown')
                            dataset = data.get('dataset_name', 'Unknown')
                            timestamp = data.get('timestamp', '')[:16].replace('T', ' ')

                            print(f"   {test_type} {result_file.name}")
                            print(f"      {model} on {dataset} ({timestamp})")

                        except Exception:
                            print(f"   âŒ {result_file.name} (ì½ê¸° ì‹¤íŒ¨)")
                else:
                    print("ğŸ“‹ ì €ì¥ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            self.logger.error(f"ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            print(f"âŒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")


    def run_status_command(self, args):
        """status ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€")
        self.show_system_status()

        # ì¶”ê°€ ìƒíƒœ ì •ë³´
        try:
            from config import get_resource_manager
            resource_manager = get_resource_manager()
            memory_usage = resource_manager.get_memory_usage()

            if memory_usage:
                print(f"\nğŸ¯ í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰:")
                for key, value in memory_usage.items():
                    if isinstance(value, float) and 'percent' in key:
                        status = "âš ï¸" if value > 80 else "âœ…"
                        print(f"   {status} {key}: {value:.1f}%")
                    elif isinstance(value, float) and 'gb' in key:
                        print(f"      {key}: {value:.2f}GB")

        except Exception as e:
            print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")


    def run_clean_command(self, args):
        """clean ëª…ë ¹ì–´ ì‹¤í–‰"""
        print("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")

        cleaned_items = []

        try:
            if args.cache or args.all:
                # CUDA ìºì‹œ ì •ë¦¬
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        cleaned_items.append("CUDA ìºì‹œ")
                except:
                    pass

                # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                gc.collect()
                cleaned_items.append("Python ê°€ë¹„ì§€")

            if args.logs or args.all:
                # ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬ (7ì¼ ì´ìƒ)
                log_dir = Path("logs")
                if log_dir.exists():
                    import time
                    current_time = time.time()
                    old_logs = []

                    for log_file in log_dir.glob("*.log"):
                        if current_time - log_file.stat().st_mtime > 7 * 24 * 3600:  # 7ì¼
                            old_logs.append(log_file)

                    for log_file in old_logs:
                        log_file.unlink()

                    if old_logs:
                        cleaned_items.append(f"{len(old_logs)}ê°œ ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼")

            if args.results or args.all:
                # ì‚¬ìš©ì í™•ì¸ í›„ ê²°ê³¼ ì •ë¦¬
                results_dir = Path("optimization_results")
                if results_dir.exists():
                    result_files = list(results_dir.glob("*.json"))
                    if result_files:
                        response = input(f"âš ï¸ {len(result_files)}ê°œ ê²°ê³¼ íŒŒì¼ì„ ì •ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                        if response.lower() == 'y':
                            for result_file in result_files:
                                result_file.unlink()
                            cleaned_items.append(f"{len(result_files)}ê°œ ê²°ê³¼ íŒŒì¼")

            # HuggingFace ìºì‹œ ì •ë¦¬ (ì„ íƒì )
            if args.all:
                hf_cache = Path.home() / ".cache" / "huggingface"
                if hf_cache.exists():
                    response = input("âš ï¸ HuggingFace ìºì‹œë¥¼ ì •ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                    if response.lower() == 'y':
                        import shutil
                        shutil.rmtree(hf_cache, ignore_errors=True)
                        cleaned_items.append("HuggingFace ìºì‹œ")

            if cleaned_items:
                print("âœ… ì •ë¦¬ ì™„ë£Œ:")
                for item in cleaned_items:
                    print(f"   - {item}")
            else:
                print("âœ… ì •ë¦¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            self.logger.error(f"ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")
            print(f"âŒ ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")


    def show_welcome_screen(self):
        """í™˜ì˜ í™”ë©´"""
        self.print_banner()
        print("ğŸ›¡ï¸ ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")

        print("\nğŸš€ ë¹ ë¥¸ ì‹œì‘ (ì•ˆì „ ëª¨ë“œ):")
        print("1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”: python safe_main.py init --auto-detect")
        print("2. í•˜ë“œì›¨ì–´ í™•ì¸: python safe_main.py hardware")
        print("3. ì‹œìŠ¤í…œ ìƒíƒœ: python safe_main.py status")
        print("4. ì•ˆì „í•œ ìµœì í™”: python safe_main.py optimize --model qwen2.5-7b --dataset korean_math --samples 10 --safe")
        print("5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬: python safe_main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 20")

        print("\nğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        print("   âœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ - ìë™ ë¦¬ì†ŒìŠ¤ ì •ë¦¬")
        print("   âœ… ìŠ¤ë ˆë“œ ì•ˆì „ì„± - ë™ì‹œì„± ë¬¸ì œ í•´ê²°")
        print("   âœ… ì˜ì¡´ì„± ì•ˆì •ì„± - Optuna ê¸°ë°˜ ìµœì í™”")
        print("   âœ… ì˜¤ë¥˜ ë³µêµ¬ - ê°•í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬")
        print("   âœ… ë³´ì•ˆ ê°•í™” - ì…ë ¥ ê²€ì¦ ë° ì•ˆì „ ëª¨ë“œ")

        print("\nâš¡ ì•ˆì „ ì‚¬ìš© íŒ:")
        print("   ğŸ›¡ï¸ ì²˜ìŒ ì‚¬ìš©: --safe ì˜µì…˜ í•„ìˆ˜")
        print("   ğŸ’¾ ë©”ëª¨ë¦¬ ì ˆì•½: --samples 10-20 ê¶Œì¥")
        print("   ğŸ› ë¬¸ì œ í•´ê²°: --debug ì˜µì…˜ í™œìš©")
        print("   ğŸ”§ ì‹œìŠ¤í…œ ì •ë¦¬: clean ëª…ë ¹ì–´ ì •ê¸° ì‹¤í–‰")

        print("\nğŸ’¡ ë„ì›€ë§:")
        print("   ì „ì²´ ëª…ë ¹ì–´: python safe_main.py --help")
        print("   ëª…ë ¹ì–´ë³„ ë„ì›€ë§: python safe_main.py [ëª…ë ¹ì–´] --help")

        # ì‹œìŠ¤í…œ ìƒíƒœ ê°„ë‹¨íˆ í‘œì‹œ
        self.show_system_status()


    async def main(self):
        """ë©”ì¸ í•¨ìˆ˜"""
        parser = self.create_argument_parser()

        # ì¸ìê°€ ì—†ìœ¼ë©´ í™˜ì˜ í™”ë©´
        if len(sys.argv) == 1:
            self.show_welcome_screen()
            return

        try:
            args = parser.parse_args()
        except SystemExit:
            return

        # ë¡œê¹… ì„¤ì •
        setup_safe_logging(args.debug)
        self.logger = logging.getLogger(__name__)

        if not args.command:
            self.print_banner()
            parser.print_help()
            return

        self.print_banner()

        # ë…ë¦½ì  ëª…ë ¹ì–´ë“¤ (ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ë¶ˆí•„ìš”)
        if args.command in ['init', 'hardware', 'list', 'status', 'clean']:
            try:
                if args.command == 'init':
                    self.run_init_command(args)
                elif args.command == 'hardware':
                    self.run_hardware_command(args)
                elif args.command == 'list':
                    self.run_list_command(args)
                elif args.command == 'status':
                    self.run_status_command(args)
                elif args.command == 'clean':
                    self.run_clean_command(args)
                return
            except KeyboardInterrupt:
                print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
            except Exception as e:
                self.logger.error(f"ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                print(f"âŒ ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                if args.debug:
                    traceback.print_exc()
                return

        # ë³µì¡í•œ ëª…ë ¹ì–´ë“¤ (ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ í•„ìš”)
        if not self.check_system_requirements():
            print("\nâš ï¸ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            if not args.safe:
                response = input("ì•ˆì „ ëª¨ë“œë¡œ ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                if response.lower() != 'y':
                    return
                args.safe = True

        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            timeout_task = None
            if args.timeout > 0:
                timeout_task = asyncio.create_task(asyncio.sleep(args.timeout))

            # ëª…ë ¹ ì‹¤í–‰
            if args.command == 'optimize':
                command_task = asyncio.create_task(self.run_optimize_command(args))
            elif args.command == 'benchmark':
                command_task = asyncio.create_task(self.run_benchmark_command(args))
            elif args.command == 'compare':
                command_task = asyncio.create_task(self.run_compare_command(args))
            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {args.command}")
                return

            # íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ëª…ë ¹ ì™„ë£Œ ëŒ€ê¸°
            if timeout_task:
                done, pending = await asyncio.wait([command_task, timeout_task], return_when=asyncio.FIRST_COMPLETED)

                if timeout_task in done:
                    command_task.cancel()
                    print(f"\nâ° ì‹œê°„ ì´ˆê³¼ ({args.timeout}ì´ˆ)")
                else:
                    timeout_task.cancel()
            else:
                await command_task

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            if args.debug:
                traceback.print_exc()
        finally:
            # ì •ë¦¬ ì‘ì—…
            print("\nğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
            try:
                if self.optimizer:
                    # ìµœì í™”ê¸° ì •ë¦¬ëŠ” ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
                    pass
                cleanup_all()
            except Exception as e:
                self.logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            print("âœ… ì •ë¦¬ ì™„ë£Œ")


def main():
    """ì§„ì…ì """
    try:
        cli = SafeCLI()
        asyncio.run(cli.main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        print("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”: --safe")
    finally:
        # ìµœì¢… ì •ë¦¬
        cleanup_all()


if __name__ == "__main__":
    main()  # !/usr/bin/env python3
"""
ì•ˆì „ì„± ê°•í™”ëœ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ë©”ì¸ CLI
ëª¨ë“  ì£¼ìš” ë¬¸ì œì ì´ í•´ê²°ëœ ì•ˆì „í•œ ë²„ì „
"""
import asyncio
import argparse
import sys
import json
import logging
import traceback
import gc
import os
import signal
import time
import shutil
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import threading
import atexit


# ì•ˆì „í•œ ë¡œê¹… ì„¤ì •
def setup_safe_logging(debug: bool = False):
    """ì•ˆì „í•œ ë¡œê¹… ì„¤ì •"""
    level = logging.DEBUG if debug else logging.INFO

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)

    # ë¡œê·¸ íŒŒì¼ëª… (ë‚ ì§œë³„)
    log_file = log_dir / f"llm_optimizer_{datetime.now().strftime('%Y%m%d')}.log"

    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ],
        force=True
    )

    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê¹… ë ˆë²¨ ì¡°ì •
    logging.getLogger('transformers').setLevel(logging.WARNING)
    logging.getLogger('torch').setLevel(logging.WARNING)
    logging.getLogger('optuna').setLevel(logging.INFO)
    logging.getLogger('urllib3').setLevel(logging.WARNING)


# ì „ì—­ ì •ë¦¬ í•¨ìˆ˜
_cleanup_functions = []
_cleanup_lock = threading.Lock()


def register_cleanup(func):
    """ì •ë¦¬ í•¨ìˆ˜ ë“±ë¡"""
    with _cleanup_lock:
        _cleanup_functions.append(func)


def cleanup_all():
    """ëª¨ë“  ë“±ë¡ëœ ì •ë¦¬ í•¨ìˆ˜ ì‹¤í–‰"""
    with _cleanup_lock:
        for func in _cleanup_functions:
            try:
                func()
            except Exception as e:
                print(f"Cleanup error: {e}")
        _cleanup_functions.clear()


# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬
def signal_handler(signum, frame):
    """ì•ˆì „í•œ ì‹œê·¸ë„ ì²˜ë¦¬"""
    print(f"\nğŸ›‘ Signal {signum} received, cleaning up...")
    cleanup_all()
    sys.exit(0)


# ì‹œê·¸ë„ ë“±ë¡ (ì•ˆì „í•˜ê²Œ)
try:
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
except ValueError:
    # ë©”ì¸ ìŠ¤ë ˆë“œê°€ ì•„ë‹Œ ê²½ìš° ë¬´ì‹œ
    pass
atexit.register(cleanup_all)


# ì•ˆì „í•œ import with fallback
def safe_import():
    """ì•ˆì „í•œ ëª¨ë“ˆ import"""
    try:
        # ê¸°ë³¸ ëª¨ë“ˆë“¤ ë¨¼ì € í™•ì¸
        import torch
        import numpy as np
        import pandas as pd

        # í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤ import
        from safe_config import ConfigManager, HardwareDetector, cleanup_resources
        from safe_optimizer import SafeOptimizer

        register_cleanup(cleanup_resources)
        return True, None

    except ImportError as e:
        error_msg = f"Critical import error: {e}"
        missing_files = []

        required_files = [
            "safe_config.py",
            "safe_model_interface.py",
            "safe_optimizer.py",
            "dataset_loader.py"
        ]

        for file in required_files:
            if not Path(file).exists():
                missing_files.append(file)

        if missing_files:
            error_msg += f"\nMissing files: {', '.join(missing_files)}"

        return False, error_msg


# Import ì‹œë„
IMPORTS_OK, IMPORT_ERROR = safe_import()


class SafeCLI:
    """ì•ˆì „í•œ CLI ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.config_manager = None
        self.optimizer = None

    def create_argument_parser(self) -> argparse.ArgumentParser:
        """CLI ì¸ì íŒŒì„œ ìƒì„±"""
        parser = argparse.ArgumentParser(
            description='ì•ˆì „í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ',
            formatter_class=argparse.RawDescriptionHelp