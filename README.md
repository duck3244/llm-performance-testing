# ğŸš€ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ

Llama, Mistral, Gemma, Qwen ë“± ì˜¤í”ˆì†ŒìŠ¤ LLMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ ìµœì í™”í•˜ê³  ë²¤ì¹˜ë§ˆí¬í•˜ëŠ” ì¢…í•© ë„êµ¬ì…ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- **ğŸ”§ íŒŒë¼ë¯¸í„° ìµœì í™”**: ë² ì´ì§€ì•ˆ/ê·¸ë¦¬ë“œì„œì¹˜/ì§„í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•œ ìë™ ìµœì í™”
- **âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**: ì†ë„, ë©”ëª¨ë¦¬, ë¹„ìš© íš¨ìœ¨ì„± ì¢…í•© ë¶„ì„
- **ğŸ’» í•˜ë“œì›¨ì–´ ìµœì í™”**: GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ìë™ ì„¤ì • ì¶”ì²œ
- **ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: CPU/GPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ì¶”ì 
- **ğŸŒ ë‹¤ì–‘í•œ ì¶”ë¡  ì—”ì§„**: Transformers, vLLM, Ollama, TGI ì§€ì›
- **ğŸ‡°ğŸ‡· í•œêµ­ì–´ íŠ¹í™”**: í•œêµ­ì–´ ìˆ˜í•™, QA, ì¶”ë¡  ë¬¸ì œ ì „ìš© í‰ê°€ì
- **ğŸ“ˆ ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”**: Plotly ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ë° ìƒì„¸ ë¶„ì„ ì°¨íŠ¸
- **ğŸ¤– ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸**: Llama, Mistral, Gemma, Qwen ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

## ğŸ¯ ì§€ì› ëª¨ë¸

### ğŸ¦™ Llama ê³„ì—´
- Meta Llama 2 (7B, 13B, 70B)
- Code Llama
- Llama 2-Chat

### ğŸŒŸ Mistral ê³„ì—´  
- Mistral 7B
- Mixtral 8x7B
- Mistral-Instruct

### ğŸ’ Gemma ê³„ì—´
- Gemma 2B, 7B
- Gemma-IT (Instruction Tuned)

### ğŸ”¥ Qwen ê³„ì—´
- Qwen 1.5 (0.5B~72B)
- Qwen-Chat
- Qwen-Math

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI Interface â”‚â”€â”€â”€â”€â”‚ Performance      â”‚â”€â”€â”€â”€â”‚ Model Interfacesâ”‚
â”‚   (main.py)     â”‚    â”‚ Optimizer        â”‚    â”‚ (Transformers,  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ (test_runner.py) â”‚    â”‚  vLLM, Ollama)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dataset       â”‚â”€â”€â”€â”€â”‚ Config Manager   â”‚â”€â”€â”€â”€â”‚ Hardware        â”‚
â”‚   Loaders       â”‚    â”‚ (config.py)      â”‚    â”‚ Monitor         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evaluators    â”‚â”€â”€â”€â”€â”‚ Result           â”‚â”€â”€â”€â”€â”‚ Visualization   â”‚
â”‚   (Korean NLP)  â”‚    â”‚ Storage          â”‚    â”‚ Dashboard       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd llm-optimization-system

# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# GPU ê°€ì†ì„ ìœ„í•œ PyTorch ì„¤ì¹˜ (CUDA 11.8 ê¸°ì¤€)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 2. ì‹œìŠ¤í…œ ì´ˆê¸°í™”

```bash
# í•˜ë“œì›¨ì–´ ìë™ ê°ì§€ì™€ í•¨ê»˜ ì´ˆê¸°í™”
python main.py init --auto-detect

# í•˜ë“œì›¨ì–´ ì •ë³´ í™•ì¸
python main.py hardware --model-size 7b
```

### 3. ëª¨ë¸ ì„¤ì •

`llm_config.json` íŒŒì¼ì—ì„œ ëª¨ë¸ ê²½ë¡œë¥¼ ì„¤ì •:

```json
{
  "models": {
    "llama2-7b": {
      "name": "llama2-7b",
      "model_path": "meta-llama/Llama-2-7b-chat-hf",
      "model_type": "transformers",
      "device": "auto",
      "dtype": "float16",
      "load_in_4bit": false
    }
  }
}
```

### 4. ì²« ë²ˆì§¸ ìµœì í™” ì‹¤í–‰

```bash
# íŒŒë¼ë¯¸í„° ìµœì í™” (ë² ì´ì§€ì•ˆ ë°©ë²•)
python main.py optimize --model llama2-7b --dataset korean_math --strategy bayesian

# ê²°ê³¼ í™•ì¸
python main.py visualize --type optimization
```

## ğŸ“– ìƒì„¸ ì‚¬ìš©ë²•

### ğŸ”§ íŒŒë¼ë¯¸í„° ìµœì í™”

```bash
# ë² ì´ì§€ì•ˆ ìµœì í™” (ê¶Œì¥)
python main.py optimize --model mistral-7b --dataset korean_qa \
  --strategy bayesian --trials 50 --samples 100

# ê·¸ë¦¬ë“œ ì„œì¹˜ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)
python main.py optimize --model gemma-7b --dataset korean_reasoning \
  --strategy grid_search --samples 50

# ì§„í™” ì•Œê³ ë¦¬ì¦˜ (ì‹¤í—˜ì )
python main.py optimize --model qwen-7b --dataset multilingual_math \
  --strategy evolutionary --trials 30
```

### âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```bash
# ê¸°ë³¸ ë²¤ì¹˜ë§ˆí¬
python main.py benchmark --model llama2-7b --dataset korean_math \
  --samples 200 --iterations 3

# ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„°ë¡œ ë²¤ì¹˜ë§ˆí¬
python main.py benchmark --model mistral-7b --dataset korean_qa \
  --temperature 0.1 --top-p 0.9 --max-tokens 512
```

### âš–ï¸ ëª¨ë¸ ë¹„êµ

```bash
# ì •í™•ë„ ê¸°ì¤€ ë¹„êµ
python main.py compare --models llama2-7b mistral-7b gemma-7b \
  --dataset korean_math --metric accuracy

# ì†ë„ ê¸°ì¤€ ë¹„êµ
python main.py compare --models llama2-7b mistral-7b \
  --dataset korean_qa --metric speed

# ë¹„ìš© íš¨ìœ¨ì„± ë¹„êµ
python main.py compare --models gemma-7b qwen-7b \
  --dataset korean_reasoning --metric cost
```

### ğŸ“Š ê²°ê³¼ ì‹œê°í™”

```bash
# ìµœì í™” ê²°ê³¼ ë¶„ì„
python main.py visualize --type optimization --filter-model llama2-7b

# ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„
python main.py visualize --type benchmark

# ì¢…í•© ëŒ€ì‹œë³´ë“œ
python main.py visualize --type dashboard

# ëª¨ë¸ ë¹„êµ ì°¨íŠ¸
python main.py visualize --type comparison
```

### ğŸ” ê²°ê³¼ ë¶„ì„

```bash
# ì „ì²´ ê²°ê³¼ ë¶„ì„
python main.py analyze --report

# íŠ¹ì • ëª¨ë¸ ë¶„ì„
python main.py analyze --model llama2-7b --report

# íŠ¹ì • ë°ì´í„°ì…‹ ë¶„ì„  
python main.py analyze --dataset korean_math --report
```

## ğŸ’¡ ìµœì í™” ì „ëµ ê°€ì´ë“œ

### ğŸ¯ ì •í™•ë„ ìš°ì„  ì„¤ì •
```
Temperature: 0.0 - 0.3
Top-p: 0.1 - 0.5
Top-k: 1 - 20
ìš©ë„: ìˆ˜í•™ ë¬¸ì œ, ì‚¬ì‹¤ í™•ì¸, ë²ˆì—­
```

### ğŸ¨ ì°½ì˜ì„± ìš°ì„  ì„¤ì •
```
Temperature: 0.7 - 1.0
Top-p: 0.8 - 0.95
Top-k: 40 - 50
ìš©ë„: ì°½ì‘, ë¸Œë ˆì¸ìŠ¤í† ë°, ëŒ€í™”
```

### âš¡ ì†ë„ ìš°ì„  ì„¤ì •
```
- vLLM ì—”ì§„ ì‚¬ìš©
- ë™ì  ë°°ì¹­ í™œì„±í™”
- Flash Attention ì‚¬ìš©
- 4-bit ì–‘ìí™” ì ìš©
```

### ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì„¤ì •
```
- load_in_4bit: true
- gradient_checkpointing: true
- cpu_offload: true (í•„ìš”ì‹œ)
```

## ğŸ”§ í•˜ë“œì›¨ì–´ë³„ ì¶”ì²œ ì„¤ì •

### ğŸ–¥ï¸ ë‹¨ì¼ GPU (8-16GB)
```json
{
  "model_size": "7B",
  "dtype": "float16",
  "load_in_4bit": true,
  "max_batch_size": 4
}
```

### ğŸ–¥ï¸ ê³ ì„±ëŠ¥ GPU (24GB+)
```json
{
  "model_size": "13B",
  "dtype": "float16", 
  "load_in_4bit": false,
  "max_batch_size": 16
}
```

### ğŸ–¥ï¸ ë‹¤ì¤‘ GPU (80GB+)
```json
{
  "model_size": "70B",
  "tensor_parallel_size": 4,
  "pipeline_parallel_size": 1,
  "dtype": "bfloat16"
}
```

### ğŸ’» CPU ì „ìš©
```json
{
  "model_size": "7B",
  "device": "cpu",
  "dtype": "float32",
  "load_in_8bit": true
}
```

## ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´

### ğŸ‡°ğŸ‡· í•œêµ­ì–´ ë°ì´í„°ì…‹
- **korean_math**: í•œêµ­ì–´ ìˆ˜í•™ ë¬¸ì œ (100ê°œ)
- **korean_qa**: í•œêµ­ì–´ ì§ˆì˜ì‘ë‹µ (150ê°œ)  
- **korean_reasoning**: í•œêµ­ì–´ ìƒì‹ ì¶”ë¡  (80ê°œ)

### ğŸŒ ë‹¤êµ­ì–´ ë°ì´í„°ì…‹
- **multilingual_math**: 4ê°œ ì–¸ì–´ ìˆ˜í•™ ë¬¸ì œ
- **gsm8k**: ì˜ì–´ ìˆ˜í•™ ë¬¸ì œ (í‘œì¤€ ë²¤ì¹˜ë§ˆí¬)
- **hellaswag**: ì˜ì–´ ìƒì‹ ì¶”ë¡ 

### ğŸ“ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¶”ê°€

```python
# data/my_dataset.json í˜•ì‹
[
  {
    "question": "ì§ˆë¬¸ ë‚´ìš©",
    "answer": "ì •ë‹µ",
    "category": "ì¹´í…Œê³ ë¦¬",
    "difficulty": "easy|medium|hard",
    "language": "ko"
  }
]
```

```bash
# ì„¤ì • íŒŒì¼ì— ë°ì´í„°ì…‹ ì¶”ê°€
# llm_config.jsonì˜ tests ì„¹ì…˜ì— ì¶”ê°€
```

## ğŸ¨ ì‹œê°í™” ì˜ˆì‹œ

### ğŸ“ˆ ìµœì í™” íŠ¸ë Œë“œ
- ëª¨ë¸ë³„ ì„±ëŠ¥ ë³€í™” ì¶”ì´
- íŒŒë¼ë¯¸í„° ìƒê´€ê´€ê³„ ë¶„ì„
- í•˜ë“œì›¨ì–´ ì‚¬ìš©ëŸ‰ íˆíŠ¸ë§µ

### âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- ì²˜ë¦¬ ì†ë„ ë¹„êµ ë§‰ëŒ€ ì°¨íŠ¸
- ì§€ì—°ì‹œê°„ ë¶„í¬ ë°•ìŠ¤ í”Œë¡¯
- ë©”ëª¨ë¦¬ vs ì„±ëŠ¥ ì‚°ì ë„

### ğŸ† ëª¨ë¸ ë¹„êµ ë ˆì´ë”
- ì •í™•ë„, ì†ë„, íš¨ìœ¨ì„±, ë¹„ìš© ì¢…í•© ë¹„êµ
- ëª¨ë¸ë³„ ê°•ì /ì•½ì  ì‹œê°í™”

## ğŸ› ï¸ ê³ ê¸‰ ì„¤ì •

### ğŸ”§ ì¶”ë¡  ì—”ì§„ë³„ ì„¤ì •

#### vLLM (ê³ ì„±ëŠ¥)
```json
{
  "model_type": "vllm",
  "tensor_parallel_size": 2,
  "gpu_memory_utilization": 0.9,
  "max_model_len": 4096
}
```

#### Ollama (ê°„í¸)
```json
{
  "model_type": "ollama", 
  "base_url": "http://localhost:11434",
  "model_path": "llama2:7b"
}
```

#### TGI (í”„ë¡œë•ì…˜)
```json
{
  "model_type": "tgi",
  "base_url": "http://localhost:3000",
  "max_batch_prefill_tokens": 4096
}
```

### ğŸ›ï¸ ê³ ê¸‰ ìµœì í™” ì˜µì…˜

```json
{
  "optimization": {
    "enable_torch_compile": true,
    "enable_bettertransformer": true,
    "dynamic_batching": true,
    "gradient_checkpointing": true
  }
}
```

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­
- CPU/GPU ì‚¬ìš©ë¥ 
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- í† í° ì²˜ë¦¬ ì†ë„
- ìš”ì²­ ì²˜ë¦¬ëŸ‰

### ìë™ ë¦¬í¬íŠ¸
- ì¼ì¼/ì£¼ê°„ ì„±ëŠ¥ ìš”ì•½
- ì´ìƒ ê°ì§€ ì•Œë¦¼
- ìµœì í™” ì¶”ì²œì‚¬í•­

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

#### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# í•´ê²°ì±…: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°, ì–‘ìí™” ì‚¬ìš©
python main.py hardware  # í˜„ì¬ GPU ë©”ëª¨ë¦¬ í™•ì¸
```

#### ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```bash
# í•´ê²°ì±…: ëª¨ë¸ ê²½ë¡œ í™•ì¸, ê¶Œí•œ ì„¤ì •
python main.py list --type models  # ëª¨ë¸ ìƒíƒœ í™•ì¸
```

#### ì„±ëŠ¥ ì €í•˜
```bash
# í•´ê²°ì±…: í•˜ë“œì›¨ì–´ ì ê²€, íŒŒë¼ë¯¸í„° ì¬ìµœì í™”
python main.py analyze --model [ëª¨ë¸ëª…] --report
```

### ë¡œê·¸ í™•ì¸
```bash
# ìƒì„¸ ë¡œê·¸ ì¶œë ¥
export PYTHONPATH=. && python -u main.py optimize --model llama2-7b --dataset korean_math -v

# ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜
ls optimization_results/
ls visualizations/
```

```bash
# ê°œë°œ í™˜ê²½ ì„¤ì •
pip install -r requirements.txt
pip install pytest black flake8 mypy

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/

# ì½”ë“œ í¬ë§·íŒ…
black . && flake8 .
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License - ìì„¸í•œ ë‚´ìš©ì€ LICENSE íŒŒì¼ ì°¸ì¡°

---

ğŸ’¡ **íŒ**: ì²˜ìŒ ì‚¬ìš©í•˜ì‹œëŠ” ê²½ìš° `python main.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”!

ğŸš€ **ì„±ëŠ¥ ìµœì í™”ë¡œ ë” ë‚˜ì€ LLM ê²½í—˜ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!**