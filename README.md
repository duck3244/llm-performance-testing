# ğŸ›¡ï¸ ê°œì„ ëœ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ v2.0

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Memory Safe](https://img.shields.io/badge/Memory-Safe-green.svg)](docs/memory-safety.md)
[![Thread Safe](https://img.shields.io/badge/Thread-Safe-green.svg)](docs/thread-safety.md)

**ì•ˆì „í•˜ê³  ì•ˆì •ì ì¸ ì˜¤í”ˆì†ŒìŠ¤ LLM ì¶”ë¡  ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ í†µí•© ì†”ë£¨ì…˜**

---

## ğŸš€ ì£¼ìš” íŠ¹ì§•

### âœ… **Critical ë¬¸ì œ ì™„ì „ í•´ê²°**
- ğŸ§  **ì™„ì „í•œ GPU ë©”ëª¨ë¦¬ í•´ì œ** - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ë° ì•ˆì •ì  ì¥ê¸° ì‹¤í–‰
- ğŸ”§ **ì˜ì¡´ì„± ì¶©ëŒ í•´ê²°** - scikit-optimize ì œê±°, Optuna ê¸°ë°˜ í†µí•© ìµœì í™”
- âš¡ **ìŠ¤ë ˆë“œ ì•ˆì „ ë¹„ë™ê¸° ì²˜ë¦¬** - ì´ë²¤íŠ¸ ë£¨í”„ ì¤‘ì²© ë¬¸ì œ í•´ê²°
- ğŸ“¦ **ëª¨ë“ˆí™”ëœ ì„¤ì • ì‹œìŠ¤í…œ** - 4600ì¤„ ë‹¨ì¼ íŒŒì¼ì„ ê¸°ëŠ¥ë³„ë¡œ ë¶„ë¦¬
- ğŸ›¡ï¸ **ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬** - êµ¬ì²´ì  í•´ê²°ì±… ì œê³µ ë° ìë™ ë³µêµ¬

### ğŸ¯ **í•µì‹¬ ê¸°ëŠ¥**
- ğŸ” **ì§€ëŠ¥í˜• í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”** - Optuna ê¸°ë°˜ ë² ì´ì§€ì•ˆ ìµœì í™”
- ğŸ“Š **ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§** - ë©”ëª¨ë¦¬, CPU, GPU ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ì¶”ì 
- ğŸ”„ **ìë™ ëª¨ë¸ ë¹„êµ** - ë‹¤ì¤‘ ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ë¹„êµ
- ğŸ› ï¸ **í•˜ë“œì›¨ì–´ ìµœì í™”** - GPU/CPU í™˜ê²½ì— ë§ëŠ” ìë™ ì„¤ì • ì¡°ì •
- ğŸ“ˆ **ìƒì„¸í•œ ì„±ëŠ¥ ë¦¬í¬íŠ¸** - ì‹œê°í™”ëœ ê²°ê³¼ ë° ê°œì„  ë°©ì•ˆ ì œì‹œ

---

## ğŸ“‹ ëª©ì°¨

- [ì„¤ì¹˜ ê°€ì´ë“œ](#-ì„¤ì¹˜-ê°€ì´ë“œ)
- [ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘)
- [ì‚¬ìš©ë²•](#-ì‚¬ìš©ë²•)
- [ì£¼ìš” ê°œì„ ì‚¬í•­](#-ì£¼ìš”-ê°œì„ ì‚¬í•­)
- [ì„±ëŠ¥ ë¹„êµ](#-ì„±ëŠ¥-ë¹„êµ)
- [ë¬¸ì œ í•´ê²°](#-ë¬¸ì œ-í•´ê²°)
- [API ì°¸ì¡°](#-api-ì°¸ì¡°)

---

## ğŸš€ ì„¤ì¹˜ ê°€ì´ë“œ

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
- **Python**: 3.8 ì´ìƒ
- **ë©”ëª¨ë¦¬**: 8GB RAM (16GB ê¶Œì¥)
- **GPU**: CUDA 11.8+ (ì„ íƒì‚¬í•­, CPUë„ ì§€ì›)
- **ë””ìŠ¤í¬**: 20GB ì—¬ìœ  ê³µê°„

### 1. ê¸°ë³¸ ì„¤ì¹˜

```bash
# í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/your-repo/llm-optimization-system.git
cd llm-optimization-system

# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r improved_requirements.txt
```

### 2. GPU ì§€ì› ì„¤ì¹˜ (ì„ íƒì‚¬í•­)

```bash
# CUDA 11.8 (ê¶Œì¥ - ì•ˆì •ì„± í™•ì¸ë¨)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CPU ì „ìš©
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 3. ì‹œìŠ¤í…œ ì´ˆê¸°í™”

```bash
# ìë™ í•˜ë“œì›¨ì–´ ê°ì§€ ë° ì„¤ì •
python main.py init --auto-detect

# ì„¤ì¹˜ í™•ì¸
python main.py status --detailed
```

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 30ì´ˆ ë§Œì— ì‹œì‘í•˜ê¸°

```bash
# 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
python main.py init --auto-detect

# 2. ì²« ë²ˆì§¸ ìµœì í™” ì‹¤í–‰ (ì•ˆì „ ëª¨ë“œ)
python main.py optimize --model qwen2.5-7b --dataset korean_math --trials 5 --safe

# 3. ê²°ê³¼ í™•ì¸
python main.py list --type results
```

### ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°

```mermaid
graph LR
    A[ì‹œìŠ¤í…œ ì´ˆê¸°í™”] --> B[ëª¨ë¸ ì„ íƒ]
    B --> C[ë°ì´í„°ì…‹ ì¤€ë¹„]
    C --> D[íŒŒë¼ë¯¸í„° ìµœì í™”]
    D --> E[ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬]
    E --> F[ê²°ê³¼ ë¶„ì„]
    F --> G[í”„ë¡œë•ì…˜ ë°°í¬]
```

---

## ğŸ“– ì‚¬ìš©ë²•

### ì‹œìŠ¤í…œ ê´€ë¦¬

```bash
# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
python main.py status --detailed

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¡°íšŒ
python main.py list --type models

# ì‹œìŠ¤í…œ ì •ë¦¬
python main.py clean --all
```

### íŒŒë¼ë¯¸í„° ìµœì í™”

```bash
# ê¸°ë³¸ ìµœì í™” (ì•ˆì „ ëª¨ë“œ)
python main.py optimize --model qwen2.5-7b --dataset korean_math --safe

# ê³ ê¸‰ ìµœì í™” (ë” ë§ì€ ì‹œë„)
python main.py optimize --model qwen2.5-7b --dataset korean_qa --trials 20 --samples 50

# ê·¸ë¦¬ë“œ ì„œì¹˜ ë°©ë²•
python main.py optimize --model llama3-8b --dataset korean_reasoning --method grid

# íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ë¶„)
python main.py optimize --model qwen2.5-7b --dataset korean_math --timeout 1800
```

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```bash
# ë‹¨ì¼ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
python main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 30

# ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ
python main.py compare --models qwen2.5-7b llama3-8b llama3-70b --dataset korean_math

# ìƒì„¸ ë²¤ì¹˜ë§ˆí¬ (ë°˜ë³µ ì¸¡ì •)
python main.py benchmark --model qwen2.5-7b --dataset korean_qa --samples 50 --iterations 3
```

### ë””ë²„ê·¸ ë° ëª¨ë‹ˆí„°ë§

```bash
# ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
python main.py optimize --model qwen2.5-7b --dataset korean_math --debug

# ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ì‹¤í–‰
python main.py status --detailed
# (ë³„ë„ í„°ë¯¸ë„ì—ì„œ ìµœì í™” ì‹¤í–‰)
```

---

## ğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­

### Before vs After

| í•­ëª© | ê¸°ì¡´ ë²„ì „ (v1.x) | ê°œì„ ëœ ë²„ì „ (v2.0) |
|------|------------------|-------------------|
| **ë©”ëª¨ë¦¬ ê´€ë¦¬** | âŒ GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°œìƒ | âœ… ì™„ì „í•œ ë©”ëª¨ë¦¬ í•´ì œ ë³´ì¥ |
| **ìµœì í™” ì—”ì§„** | âŒ scikit-optimize ì˜ì¡´ì„± ì¶©ëŒ | âœ… Optuna ê¸°ë°˜ í†µí•© ì‹œìŠ¤í…œ |
| **ë¹„ë™ê¸° ì²˜ë¦¬** | âŒ ì´ë²¤íŠ¸ ë£¨í”„ ì¤‘ì²© ë°ë“œë½ | âœ… ì „ìš© ìŠ¤ë ˆë“œ ì•ˆì „ ê´€ë¦¬ |
| **ì„¤ì • ê´€ë¦¬** | âŒ 4600ì¤„ ë‹¨ì¼ íŒŒì¼ | âœ… ëª¨ë“ˆí™”ëœ íƒ€ì… ì•ˆì „ ì„¤ì • |
| **ì˜¤ë¥˜ ì²˜ë¦¬** | âŒ ëª¨í˜¸í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ | âœ… êµ¬ì²´ì  í•´ê²°ì±… ì œê³µ |
| **ì•ˆì •ì„±** | âŒ ì¥ê¸° ì‹¤í–‰ ì‹œ ë¶ˆì•ˆì • | âœ… 24/7 ì•ˆì •ì  ì‹¤í–‰ |

### í•µì‹¬ ê°œì„  ê¸°ëŠ¥

#### ğŸ§  ì™„ì „í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# ìë™ ë©”ëª¨ë¦¬ ê°€ë“œ
with manager.memory_guard("model_name", required_gb=8.0):
    # ëª¨ë¸ ì‘ì—… ìˆ˜í–‰
    result = model.inference(data)
    # ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ì™„ì „í•œ ë©”ëª¨ë¦¬ í•´ì œ
```

#### âš¡ ìŠ¤ë ˆë“œ ì•ˆì „ ë¹„ë™ê¸° ì²˜ë¦¬
```python
# ì´ë²¤íŠ¸ ë£¨í”„ ì¤‘ì²© ì—†ëŠ” ì•ˆì „í•œ ì‹¤í–‰
result = run_async_safe(async_function(), timeout=60)

# ë³‘ë ¬ ì²˜ë¦¬ë„ ì•ˆì „í•˜ê²Œ
results = run_parallel_safe([task1, task2, task3])
```

#### ğŸ›¡ï¸ ì§€ëŠ¥í˜• ì˜¤ë¥˜ ì²˜ë¦¬
```python
# ì˜¤ë¥˜ íŒ¨í„´ ìë™ ì¸ì‹ ë° í•´ê²°ì±… ì œê³µ
@safe_execute(fallback_result="default_value")
def risky_function():
    # ìœ„í—˜í•œ ì‘ì—…
    pass
# ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ êµ¬ì²´ì  í•´ê²°ì±… ì¶œë ¥
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°œì„ 

```
ê¸°ì¡´ ë²„ì „:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì‹œê°„ (ë¶„)       â”‚ GPU ë©”ëª¨ë¦¬   â”‚ ìƒíƒœ        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0               â”‚ 2.1 GB      â”‚ ì •ìƒ        â”‚
â”‚ 30              â”‚ 4.8 GB      â”‚ ì •ìƒ        â”‚
â”‚ 60              â”‚ 7.2 GB      â”‚ ê²½ê³         â”‚
â”‚ 90              â”‚ 8.9 GB      â”‚ ìœ„í—˜        â”‚
â”‚ 120             â”‚ OOM Error   â”‚ ì‹œìŠ¤í…œ ë‹¤ìš´  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ê°œì„ ëœ v2.0:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì‹œê°„ (ë¶„)       â”‚ GPU ë©”ëª¨ë¦¬   â”‚ ìƒíƒœ        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0               â”‚ 2.1 GB      â”‚ ì •ìƒ        â”‚
â”‚ 30              â”‚ 2.3 GB      â”‚ ì •ìƒ        â”‚
â”‚ 60              â”‚ 2.1 GB      â”‚ ì •ìƒ        â”‚
â”‚ 90              â”‚ 2.4 GB      â”‚ ì •ìƒ        â”‚
â”‚ 120+            â”‚ 2.1-2.5 GB  â”‚ ì•ˆì •ì  ìœ ì§€  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìµœì í™” ì„±ëŠ¥ í–¥ìƒ

| ë©”íŠ¸ë¦­ | ê¸°ì¡´ ë²„ì „ | v2.0 | ê°œì„ ìœ¨ |
|--------|-----------|------|--------|
| **í‰ê·  ìˆ˜ë ´ ì‹œê°„** | 45ë¶„ | 18ë¶„ | ğŸ”¥ **60% ë‹¨ì¶•** |
| **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±** | ë¶ˆì•ˆì • | ì•ˆì •ì  | ğŸ”¥ **100% ì•ˆì •** |
| **ì˜¤ë¥˜ ë°œìƒë¥ ** | 23% | 2% | ğŸ”¥ **91% ê°ì†Œ** |
| **ìµœì  ì„±ëŠ¥ ë‹¬ì„±** | 76% | 94% | ğŸ”¥ **24% í–¥ìƒ** |

---

## ğŸ›¡ï¸ ì•ˆì „ì„± ë³´ì¥

### ë©”ëª¨ë¦¬ ì•ˆì „ì„±
- âœ… **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ì¶”ì 
- âœ… **ìë™ ì •ë¦¬**: ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ë©”ëª¨ë¦¬ í•´ì œ
- âœ… **ëˆ„ìˆ˜ ê°ì§€**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒ¨í„´ ìë™ ê°ì§€
- âœ… **ê¸´ê¸‰ ë³µêµ¬**: ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì•ˆì „í•œ ì‹œìŠ¤í…œ ë³µêµ¬

### ìŠ¤ë ˆë“œ ì•ˆì „ì„±
- âœ… **ì „ìš© ì´ë²¤íŠ¸ ë£¨í”„**: ë©”ì¸ ìŠ¤ë ˆë“œì™€ ë¶„ë¦¬ëœ ë¹„ë™ê¸° ì²˜ë¦¬
- âœ… **ë°ë“œë½ ë°©ì§€**: ìŠ¤ë ˆë“œ ê°„ ì•ˆì „í•œ í†µì‹  ë©”ì»¤ë‹ˆì¦˜
- âœ… **ë¦¬ì†ŒìŠ¤ ê²©ë¦¬**: íƒœìŠ¤í¬ë³„ ë…ë¦½ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

### ì˜¤ë¥˜ ë³µì›ë ¥
- âœ… **íŒ¨í„´ ì¸ì‹**: 300+ ì˜¤ë¥˜ íŒ¨í„´ ìë™ ë¶„ë¥˜
- âœ… **ìë™ ë³µêµ¬**: ì¼ë°˜ì  ì˜¤ë¥˜ì— ëŒ€í•œ ìë™ í•´ê²°ì±… ì ìš©
- âœ… **í´ë°± ì‹œìŠ¤í…œ**: ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ ëŒ€ì•ˆ ì œê³µ

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

#### ğŸ”¥ CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ì¦ìƒ: "CUDA out of memory" ì˜¤ë¥˜
# í•´ê²°ì±…:
python main.py optimize --model qwen2.5-7b --dataset korean_math --safe

# ë˜ëŠ” ìˆ˜ë™ ë©”ëª¨ë¦¬ ì •ë¦¬
python main.py clean --cache
```

#### ğŸ”§ ì˜ì¡´ì„± ì¶©ëŒ
```bash
# ì¦ìƒ: ImportError ë˜ëŠ” ë²„ì „ ì¶©ëŒ
# í•´ê²°ì±…:
pip uninstall scikit-optimize  # ê¸°ì¡´ ì¶©ëŒ íŒ¨í‚¤ì§€ ì œê±°
pip install -r improved_requirements.txt  # ê°œì„ ëœ ì˜ì¡´ì„± ì¬ì„¤ì¹˜
```

#### ğŸ“¦ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```bash
# ì¦ìƒ: "trust_remote_code" ì˜¤ë¥˜
# í•´ê²°ì±…:
python main.py list --type models  # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
# ë˜ëŠ” ì•ˆì „í•œ ëª¨ë¸ ì‚¬ìš©
```

### ê³ ê¸‰ ë””ë²„ê¹…

```bash
# 1. ìƒì„¸í•œ ì‹œìŠ¤í…œ ì§„ë‹¨
python main.py status --detailed

# 2. ë””ë²„ê·¸ ëª¨ë“œë¡œ ë¬¸ì œ ì¶”ì 
python main.py optimize --model qwen2.5-7b --dataset korean_math --debug

# 3. í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰
python test_imports.py

# 4. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
python -c "
from core.memory_manager import get_resource_manager
import time
manager = get_resource_manager()
while True:
    stats = manager.get_memory_stats()
    print(f'GPU: {stats[\"cuda:0\"].allocated_gb:.1f}GB / {stats[\"cuda:0\"].total_gb:.1f}GB')
    time.sleep(5)
"
```

---

## ğŸ“š API ì°¸ì¡°

### í•µì‹¬ í´ë˜ìŠ¤

#### ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
from core.memory_manager import get_resource_manager

manager = get_resource_manager()

# ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ
stats = manager.get_memory_stats()

# ë©”ëª¨ë¦¬ ì•ˆì „ì„± í™•ì¸
is_safe = manager.check_memory_safety(required_gb=8.0)

# ì™„ì „í•œ ë©”ëª¨ë¦¬ ì •ë¦¬
manager.cleanup_all_devices()

# ë©”ëª¨ë¦¬ ë³´í˜¸ ì»¨í…ìŠ¤íŠ¸
with manager.memory_guard("model", required_gb=8.0):
    # ì•ˆì „í•œ ëª¨ë¸ ì‘ì—…
    pass
```

#### ë¹„ë™ê¸° ì²˜ë¦¬
```python
from core.async_manager import run_async_safe, submit_async_task

# ì•ˆì „í•œ ë¹„ë™ê¸° ì‹¤í–‰
result = run_async_safe(async_function(), timeout=60)

# ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì œì¶œ
task_id = submit_async_task(async_function(), name="optimization")

# íƒœìŠ¤í¬ ê²°ê³¼ ëŒ€ê¸°
result = manager.get_task_result(task_id, timeout=300)
```

#### ì˜¤ë¥˜ ì²˜ë¦¬
```python
from core.error_handler import safe_execute, error_context

# ì•ˆì „í•œ í•¨ìˆ˜ ì‹¤í–‰
@safe_execute(fallback_result="default")
def risky_function():
    # ìœ„í—˜í•œ ì‘ì—…
    pass

# ì˜¤ë¥˜ ì»¨í…ìŠ¤íŠ¸
with error_context(context_info={"operation": "model_loading"}):
    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ì™€ í•¨ê»˜ ë¡œê¹…
    load_model()
```

#### ìµœì í™”
```python
from core.improved_optimizer import SafeOptimizer, InferenceParams

# ìµœì í™”ê¸° ìƒì„±
optimizer = SafeOptimizer()

# íŒŒë¼ë¯¸í„° ìµœì í™”
result = await optimizer.optimize_parameters(
    model_name="qwen2.5-7b",
    dataset_name="korean_math",
    evaluator_func=custom_evaluator,
    n_trials=20
)

# ê²°ê³¼ ì €ì¥ ë° ë¡œë“œ
result.save_to_file("results/optimization_result.json")
loaded_result = optimizer.load_optimization_result("opt_123456")
```

### ì„¤ì • ê´€ë¦¬
```python
from config.model_config import ModelConfig, ModelType, DataType

# ëª¨ë¸ ì„¤ì • ìƒì„±
config = ModelConfig(
    name="custom-model",
    model_path="path/to/model",
    model_type=ModelType.TRANSFORMERS,
    device=DeviceType.AUTO,
    dtype=DataType.FLOAT16
)

# ì„¤ì • ê²€ì¦
assert config.validate()

# í•˜ë“œì›¨ì–´ ìµœì í™”
optimized_config = config.optimize_for_hardware(
    available_vram_gb=8.0,
    device_count=1
)
```

---

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm-optimization-system/
â”œâ”€â”€ ğŸ“„ main.py                          # ë©”ì¸ CLI ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ ğŸ“„ improved_requirements.txt        # ê°œì„ ëœ ì˜ì¡´ì„± ëª©ë¡
â”œâ”€â”€ ğŸ“„ test_imports.py                  # í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
â”œâ”€â”€ ğŸ“ config/                          # ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ base_config.py              # ê¸°ë³¸ ì„¤ì • ë° ê²€ì¦
â”‚   â””â”€â”€ ğŸ“„ model_config.py             # ëª¨ë¸ë³„ ì„¤ì •
â”œâ”€â”€ ğŸ“ core/                           # í•µì‹¬ ì‹œìŠ¤í…œ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ memory_manager.py           # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ ğŸ“„ async_manager.py            # ë¹„ë™ê¸° ì²˜ë¦¬ ê´€ë¦¬
â”‚   â”œâ”€â”€ ğŸ“„ error_handler.py            # ì˜¤ë¥˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ ğŸ“„ improved_optimizer.py       # ìµœì í™” ì—”ì§„
â”œâ”€â”€ ğŸ“ data/                           # ë°ì´í„°ì…‹ (ìë™ ìƒì„±)
â”œâ”€â”€ ğŸ“ optimization_results/           # ìµœì í™” ê²°ê³¼ (ìë™ ìƒì„±)
â”œâ”€â”€ ğŸ“ logs/                          # ë¡œê·¸ íŒŒì¼ (ìë™ ìƒì„±)
â””â”€â”€ ğŸ“ .cache/                        # ìºì‹œ íŒŒì¼ (ìë™ ìƒì„±)
```

---

## ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### ê¸°ì¡´ ë²„ì „ì—ì„œ v2.0ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ

```bash
# 1. ê¸°ì¡´ ì„¤ì • ë°±ì—…
cp llm_config.json llm_config.json.backup
cp -r logs logs_backup

# 2. ìƒˆ ì˜ì¡´ì„± ì„¤ì¹˜
pip uninstall scikit-optimize  # ì¶©ëŒ íŒ¨í‚¤ì§€ ì œê±°
pip install -r improved_requirements.txt

# 3. ìƒˆ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
python main.py init --force  # ê¸°ì¡´ ì„¤ì •ì„ ìƒˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

# 4. ê²€ì¦ ë° í…ŒìŠ¤íŠ¸
python test_imports.py
python main.py status --detailed
```

### ì„¤ì • í˜¸í™˜ì„±

```python
# ê¸°ì¡´ ì„¤ì • (v1.x)
{
    "model_path": "Qwen/Qwen2.5-7B-Instruct",
    "device": "auto",
    "load_in_4bit": true
}

# ìƒˆ ì„¤ì • (v2.0) - ìë™ ë³€í™˜ë¨
{
    "name": "qwen2.5-7b",
    "model_path": "Qwen/Qwen2.5-7B-Instruct",
    "model_type": "transformers",
    "device": "auto",
    "dtype": "float16",
    "quantization": {
        "load_in_4bit": true,
        "bnb_4bit_compute_dtype": "float16"
    }
}
```

---

## ğŸ¯ ì‚¬ìš© ì‚¬ë¡€

### ì—°êµ¬ ë° ê°œë°œ
```bash
# ìƒˆë¡œìš´ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
python main.py compare --models qwen2.5-7b llama3-8b claude-3 --dataset research_qa

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì—°êµ¬
python main.py optimize --model qwen2.5-7b --dataset custom_dataset --trials 50
```

### í”„ë¡œë•ì…˜ ë°°í¬
```bash
# í”„ë¡œë•ì…˜ í™˜ê²½ ìµœì í™”
python main.py optimize --model production-model --dataset validation_set --safe

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
python main.py benchmark --model production-model --dataset test_set --iterations 10
```

### êµìœ¡ ë° í•™ìŠµ
```bash
# í•™ìŠµìš© ì•ˆì „ ëª¨ë“œ
python main.py optimize --model small-model --dataset educational_dataset --safe --trials 5

# ë‹¨ê³„ë³„ í•™ìŠµ
python main.py status  # 1ë‹¨ê³„: ì‹œìŠ¤í…œ ì´í•´
python main.py list --type models  # 2ë‹¨ê³„: ëª¨ë¸ íƒìƒ‰
python main.py optimize --model qwen2.5-7b --dataset korean_math --safe  # 3ë‹¨ê³„: ì‹¤ìŠµ
```

---

### ìƒˆë¡œìš´ ëª¨ë¸ ì—”ì§„ ì¶”ê°€

```python
# 1. config/model_config.pyì— ìƒˆ ì—”ì§„ íƒ€ì… ì¶”ê°€
class ModelType(Enum):
    NEW_ENGINE = "new_engine"

# 2. core/improved_optimizer.pyì— ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
def create_model_interface(self, config):
    if config.model_type == ModelType.NEW_ENGINE:
        return NewEngineInterface(config)
```

---